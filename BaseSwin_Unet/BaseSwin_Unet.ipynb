{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6232e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after class definition on line 63 (318673341.py, line 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 64\u001b[1;36m\u001b[0m\n\u001b[1;33m    def __init__(self, input_channels=3, num_classes=1):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after class definition on line 63\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import SwinConfig, SwinModel\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Cấu hình chung ---\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 12\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 1000 # Số epoch bạn muốn huấn luyện\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# --- Định nghĩa Mô hình (Tái sử dụng từ mã của bạn, với một số điều chỉnh) ---\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # Sử dụng nn.Upsample + Conv2d(1x1) để tránh checkerboard artifacts\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        # ConvBlock sẽ nhận đầu vào từ upsample và skip_features (nếu có)\n",
    "        self.conv_block = ConvBlock(out_channels + skip_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, skip_features=None):\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        if skip_features is not None:\n",
    "            # Đảm bảo kích thước không gian của skip_features khớp với x\n",
    "            if x.shape[2:] != skip_features.shape[2:]:\n",
    "                skip_features = F.interpolate(skip_features, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "            x = torch.cat([x, skip_features], dim=1)\n",
    "        \n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "class SwinUNet(nn.Module):\n",
    "    class SwinUNet(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.IMG_SIZE = IMG_SIZE\n",
    "\n",
    "        config = SwinConfig(image_size=self.IMG_SIZE, num_channels=input_channels,\n",
    "                            patch_size=4, embed_dim=128, depths=[2, 2, 18, 2], num_heads=[4, 8, 16, 32],\n",
    "                            window_size=7, mlp_ratio=4., qkv_bias=True, hidden_dropout_prob=0.0,\n",
    "                            attention_probs_dropout_prob=0.0, drop_path_rate=0.1,\n",
    "                            hidden_act=\"gelu\", use_absolute_embeddings=False,\n",
    "                            patch_norm=True, initializer_range=0.02, layer_norm_eps=1e-05,\n",
    "                            out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"])\n",
    "        self.swin = SwinModel(config)\n",
    "\n",
    "        # Bottleneck: từ hidden_states[3] (H/32 x W/32)\n",
    "        # config.embed_dim * 8 = 128 * 8 = 1024\n",
    "        self.bottleneck = ConvBlock(config.embed_dim * 8, config.embed_dim * 8)\n",
    "\n",
    "        # Decoder 4: upsample từ H/32 -> H/16. Skip từ hidden_states[2] (H/16)\n",
    "        # in_channels: từ bottleneck (1024), skip_channels: từ hidden_states[2] (512), out_channels: 512\n",
    "        self.decoder4 = DecoderBlock(in_channels=config.embed_dim * 8, skip_channels=config.embed_dim * 4, out_channels=config.embed_dim * 4)\n",
    "\n",
    "        # Decoder 3: upsample từ H/16 -> H/8. Skip từ hidden_states[1] (H/8)\n",
    "        # in_channels: từ decoder4 (512), skip_channels: từ hidden_states[1] (256), out_channels: 256\n",
    "        self.decoder3 = DecoderBlock(in_channels=config.embed_dim * 4, skip_channels=config.embed_dim * 2, out_channels=config.embed_dim * 2)\n",
    "\n",
    "        # Decoder 2: upsample từ H/8 -> H/4. Skip từ hidden_states[0] (H/4)\n",
    "        # in_channels: từ decoder3 (256), skip_channels: từ hidden_states[0] (128), out_channels: 128\n",
    "        self.decoder2 = DecoderBlock(in_channels=config.embed_dim * 2, skip_channels=config.embed_dim * 1, out_channels=config.embed_dim * 1)\n",
    "\n",
    "        # Decoder 1: upsample từ H/4 -> H/2. Không có skip trực tiếp từ Swin Encoder ở cấp độ này\n",
    "        # in_channels: từ decoder2 (128), skip_channels: 0, out_channels: 64\n",
    "        self.decoder1 = DecoderBlock(in_channels=config.embed_dim * 1, skip_channels=0, out_channels=config.embed_dim // 2)\n",
    "\n",
    "        # Final Upsample: upsample từ H/2 -> H. Không có skip\n",
    "        # in_channels: từ decoder1 (64), skip_channels: 0, out_channels: 32\n",
    "        self.final_upsample = DecoderBlock(in_channels=config.embed_dim // 2, skip_channels=0, out_channels=config.embed_dim // 4)\n",
    "\n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(config.embed_dim // 4, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.swin(pixel_values=x, output_hidden_states=True)\n",
    "        \n",
    "        # Lấy các hidden_states tương ứng với các cấp độ giải mã\n",
    "        # hidden_states[0]: H/4 x W/4, 96 kênh\n",
    "        # hidden_states[1]: H/8 x W/8, 192 kênh\n",
    "        # hidden_states[2]: H/16 x W/16, 384 kênh\n",
    "        # hidden_states[3]: H/32 x W/32, 768 kênh (thường dùng cho bottleneck)\n",
    "        # hidden_states[4]: Đây là output của Stage 3 trước Layernorm (giống hidden_states[3])\n",
    "        \n",
    "        # Chuyển đổi các hidden_states từ format (batch, num_patches, embed_dim)\n",
    "        # sang (batch, embed_dim, height, width)\n",
    "        \n",
    "        # Skip connection cho Decoder2 (H/4)\n",
    "        hs0 = outputs.hidden_states[0]\n",
    "        batch_size, num_patches, embed_dim = hs0.shape\n",
    "        side = int(np.sqrt(num_patches)) # side = IMG_SIZE / 4 = 256 / 4 = 64\n",
    "        skip0 = hs0.permute(0, 2, 1).reshape(batch_size, embed_dim, side, side) # (B, 96, 64, 64)\n",
    "\n",
    "        # Skip connection cho Decoder3 (H/8)\n",
    "        hs1 = outputs.hidden_states[1]\n",
    "        batch_size, num_patches, embed_dim = hs1.shape\n",
    "        side = int(np.sqrt(num_patches)) # side = IMG_SIZE / 8 = 32\n",
    "        skip1 = hs1.permute(0, 2, 1).reshape(batch_size, embed_dim, side, side) # (B, 192, 32, 32)\n",
    "\n",
    "        # Skip connection cho Decoder4 (H/16)\n",
    "        hs2 = outputs.hidden_states[2]\n",
    "        batch_size, num_patches, embed_dim = hs2.shape\n",
    "        side = int(np.sqrt(num_patches)) # side = IMG_SIZE / 16 = 16\n",
    "        skip2 = hs2.permute(0, 2, 1).reshape(batch_size, embed_dim, side, side) # (B, 384, 16, 16)\n",
    "\n",
    "        # Bottleneck từ hidden_states[3] hoặc [4]. [4] thường là output cuối cùng của encoder\n",
    "        # mà bạn đã dùng trong mã inference, nên tôi sẽ giữ nguyên.\n",
    "        x_bottleneck = outputs.hidden_states[4]\n",
    "        batch_size, num_patches, embed_dim = x_bottleneck.shape\n",
    "        side = int(np.sqrt(num_patches)) # side = IMG_SIZE / 32 = 8\n",
    "        x_bottleneck = x_bottleneck.permute(0, 2, 1).reshape(batch_size, embed_dim, side, side) # (B, 768, 8, 8)\n",
    "        \n",
    "        x = self.bottleneck(x_bottleneck) # (B, 768, 8, 8)\n",
    "\n",
    "        # Giải mã\n",
    "        x = self.decoder4(x, skip2) # in (768, 8, 8), skip (384, 16, 16) -> out (384, 16, 16)\n",
    "        x = self.decoder3(x, skip1) # in (384, 16, 16), skip (192, 32, 32) -> out (192, 32, 32)\n",
    "        x = self.decoder2(x, skip0) # in (192, 32, 32), skip (96, 64, 64) -> out (96, 64, 64)\n",
    "        x = self.decoder1(x)       # in (96, 64, 64), no skip           -> out (48, 128, 128)\n",
    "        x = self.final_upsample(x) # in (48, 128, 128), no skip         -> out (24, 256, 256)\n",
    "\n",
    "        outputs = self.final_conv(x) # (B, 1, 256, 256)\n",
    "        # Không áp dụng sigmoid ở đây. BCEWithLogitsLoss sẽ làm điều đó.\n",
    "        # Nếu bạn muốn dự đoán đầu ra 0-1, bạn có thể áp dụng sigmoid sau khi loss được tính.\n",
    "        # outputs = self.sigmoid(outputs) \n",
    "\n",
    "        return outputs\n",
    "\n",
    "# --- Định nghĩa Hàm Mất Mát (Loss Functions) ---\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Flatten inputs and targets\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # Calculate intersection and union\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice # Return (1 - Dice Coefficient)\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss() # Sử dụng cho logits (output chưa sigmoid)\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # BCEWithLogitsLoss nhận logits và targets. Targets phải là float.\n",
    "        bce = self.bce_loss(predictions, targets)\n",
    "        \n",
    "        # Để tính Dice Loss, chúng ta cần chuyển predictions thành xác suất (0-1)\n",
    "        # bằng sigmoid, vì Dice hoạt động tốt nhất trên xác suất hoặc nhị phân.\n",
    "        predictions_sigmoid = torch.sigmoid(predictions)\n",
    "        dice = self.dice_loss(predictions_sigmoid, targets)\n",
    "        \n",
    "        return self.bce_weight * bce + self.dice_weight * dice\n",
    "\n",
    "# --- Giả lập Dataset (thay thế bằng Dataset thực của bạn) ---\n",
    "class DummySegmentationDataset(Dataset):\n",
    "    def __init__(self, num_samples=100, img_size=IMG_SIZE):\n",
    "        self.num_samples = num_samples\n",
    "        self.img_size = img_size\n",
    "        print(f\"Khởi tạo DummyDataset với {num_samples} mẫu.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tạo ảnh giả (ngẫu nhiên)\n",
    "        image = np.random.rand(self.img_size, self.img_size, 3).astype(np.float32)\n",
    "        # Tạo mask giả (ngẫu nhiên nhị phân)\n",
    "        mask = (np.random.rand(self.img_size, self.img_size) > 0.5).astype(np.float32)\n",
    "\n",
    "        # Chuyển đổi sang định dạng PyTorch (C, H, W)\n",
    "        image_tensor = torch.from_numpy(image).permute(2, 0, 1)\n",
    "        mask_tensor = torch.from_numpy(mask).unsqueeze(0) # Thêm chiều kênh\n",
    "\n",
    "        return image_tensor, mask_tensor\n",
    "\n",
    "# --- Tiền xử lý ảnh (giống như trong file inference) ---\n",
    "# Hàm này có thể được tích hợp vào Dataset của bạn để xử lý ảnh thực\n",
    "def load_and_preprocess_image_and_mask(image_path, mask_path, target_size=IMG_SIZE, window_size=4):\n",
    "    img = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) # Đọc mask dưới dạng ảnh grayscale\n",
    "\n",
    "    if img is None or mask is None:\n",
    "        raise ValueError(f\"Không thể đọc tệp ảnh hoặc mask: {image_path}, {mask_path}\")\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    new_h = max(target_size, ((h + window_size - 1) // window_size) * window_size)\n",
    "    new_w = max(target_size, ((w + window_size - 1) // window_size) * window_size)\n",
    "\n",
    "    # Padding ảnh\n",
    "    padded_img = np.zeros((new_h, new_w, 3), dtype=img.dtype)\n",
    "    padded_img[:h, :w, :] = img\n",
    "    cropped_img = padded_img[:target_size, :target_size, :]\n",
    "\n",
    "    # Padding mask\n",
    "    padded_mask = np.zeros((new_h, new_w), dtype=mask.dtype)\n",
    "    padded_mask[:h, :w] = mask\n",
    "    cropped_mask = padded_mask[:target_size, :target_size]\n",
    "\n",
    "    img_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "    img_processed = img_rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Chuẩn hóa mask về 0-1 và đảm bảo là float\n",
    "    mask_processed = (cropped_mask > 127).astype(np.float32) # Giả sử mask nhị phân (0 hoặc 255)\n",
    "\n",
    "    img_tensor = torch.from_numpy(img_processed).permute(2, 0, 1)\n",
    "    mask_tensor = torch.from_numpy(mask_processed).unsqueeze(0) # Thêm chiều kênh\n",
    "    \n",
    "    return img_tensor, mask_tensor\n",
    "\n",
    "# --- Dataset thực tế (ví dụ cho cấu trúc thư mục) ---\n",
    "class RealSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, img_size=IMG_SIZE):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.image_filenames = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        self.mask_filenames = sorted([f for f in os.listdir(mask_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "        # Đảm bảo số lượng ảnh và mask khớp nhau\n",
    "        if len(self.image_filenames) != len(self.mask_filenames):\n",
    "            print(f\"Cảnh báo: Số lượng ảnh ({len(self.image_filenames)}) và mask ({len(self.mask_filenames)}) không khớp.\")\n",
    "            # Bạn có thể thêm logic để lọc ra các cặp không khớp hoặc báo lỗi.\n",
    "\n",
    "        print(f\"Tìm thấy {len(self.image_filenames)} cặp ảnh/mask trong thư mục.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_filenames[idx]\n",
    "        mask_name = self.mask_filenames[idx] # Giả định tên mask tương ứng với tên ảnh\n",
    "\n",
    "        image_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name) # Đây là giả định quan trọng, cần đảm bảo tên mask khớp\n",
    "\n",
    "        image, mask = load_and_preprocess_image_and_mask(image_path, mask_path, self.img_size)\n",
    "        return image, mask\n",
    "\n",
    "# --- Chỉ số đánh giá (Metrics) ---\n",
    "def dice_coefficient(predictions, targets, smooth=1e-6):\n",
    "    # Áp dụng sigmoid và làm tròn để có mask nhị phân cho đánh giá\n",
    "    predictions = (torch.sigmoid(predictions) > 0.5).float()\n",
    "    \n",
    "    # Flatten tensors\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    \n",
    "    intersection = (predictions * targets).sum()\n",
    "    union = predictions.sum() + targets.sum()\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "\n",
    "def iou_score(predictions, targets, smooth=1e-6):\n",
    "    predictions = (torch.sigmoid(predictions) > 0.5).float()\n",
    "\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "\n",
    "    intersection = (predictions * targets).sum()\n",
    "    total = predictions.sum() + targets.sum()\n",
    "    union = total - intersection\n",
    "    \n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou\n",
    "\n",
    "# --- Hàm Huấn luyện ---\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, checkpoint_dir):\n",
    "    best_val_iou = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_dice': [], 'val_iou': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Chế độ huấn luyện\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "\n",
    "        for images, masks in train_bar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device) # Mask phải là float (0.0 hoặc 1.0)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        # --- Đánh giá trên tập Validation ---\n",
    "        model.eval() # Chế độ đánh giá\n",
    "        val_loss = 0.0\n",
    "        val_dice_scores = []\n",
    "        val_iou_scores = []\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "\n",
    "        with torch.no_grad(): # Không tính gradient trong quá trình đánh giá\n",
    "            for images, masks in val_bar:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                dice = dice_coefficient(outputs, masks)\n",
    "                iou = iou_score(outputs, masks)\n",
    "                val_dice_scores.append(dice.item())\n",
    "                val_iou_scores.append(iou.item())\n",
    "                val_bar.set_postfix(val_loss=loss.item(), dice=dice.item(), iou=iou.item())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_dice = np.mean(val_dice_scores)\n",
    "        avg_val_iou = np.mean(val_iou_scores)\n",
    "        \n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_dice'].append(avg_val_dice)\n",
    "        history['val_iou'].append(avg_val_iou)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Val Dice: {avg_val_dice:.4f}, Val IoU: {avg_val_iou:.4f}\")\n",
    "\n",
    "        # Lưu mô hình tốt nhất dựa trên IoU\n",
    "        if avg_val_iou > best_val_iou:\n",
    "            best_val_iou = avg_val_iou\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'swin_unet_best_pytorch.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_val_loss,\n",
    "                'iou': avg_val_iou,\n",
    "                'dice': avg_val_dice,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Đã lưu mô hình tốt nhất với Val IoU: {best_val_iou:.4f} tại {checkpoint_path}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# --- Khởi tạo và Bắt đầu Huấn luyện ---\n",
    "if __name__ == '__main__':\n",
    "    print(f\"Thiết bị đang sử dụng: {DEVICE}\")\n",
    "\n",
    "    # --- Khởi tạo Dataset và DataLoader ---\n",
    "    # THAY THẾ DUMMY DATASET BẰNG REAL DATASET CỦA BẠN\n",
    "    # Ví dụ với cấu trúc thư mục như UDTIRI-Crack bạn nhắc đến:\n",
    "    # UDTIRI-Crack/UDTIRI-Crack Generalization2/image/\n",
    "    # UDTIRI-Crack/UDTIRI-Crack Generalization2/mask/\n",
    "\n",
    "    # Hãy đảm bảo rằng tên tệp ảnh và mask khớp nhau, ví dụ:\n",
    "    # image/019.png -> mask/019.png\n",
    "\n",
    "    # Dùng DummyDataset để test code nhanh nếu chưa có dữ liệu sẵn\n",
    "    # train_dataset = DummySegmentationDataset(num_samples=100)\n",
    "    # val_dataset = DummySegmentationDataset(num_samples=20)\n",
    "    \n",
    "    # Ví dụ sử dụng RealSegmentationDataset (thay đổi đường dẫn phù hợp)\n",
    "    try:\n",
    "        # Thay đổi đường dẫn này cho phù hợp với máy tính của bạn\n",
    "        base_data_path = r'C:\\Users\\Admin\\Documents\\Python Project\\DPL Crack detection\\archive (2)\\UDTIRI-Crack\\UDTIRI-Crack Generalization2'\n",
    "        train_image_dir = os.path.join(base_data_path, 'image')\n",
    "        train_mask_dir = os.path.join(base_data_path, 'mask')\n",
    "\n",
    "        # Nếu bạn có tập validation riêng, hãy tạo các thư mục tương ứng\n",
    "        # val_image_dir = os.path.join(base_data_path, 'val_images')\n",
    "        # val_mask_dir = os.path.join(base_data_path, 'val_masks')\n",
    "\n",
    "        # Tạm thời sử dụng cùng một thư mục cho cả train/val để demo, NHƯNG KHÔNG NÊN LÀM VẬY TRONG THỰC TẾ\n",
    "        # Bạn nên chia dữ liệu thành train/val/test một cách hợp lý.\n",
    "        full_dataset = RealSegmentationDataset(image_dir=train_image_dir, mask_dir=train_mask_dir)\n",
    "        \n",
    "        # Chia dataset thành train và validation\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "        print(f\"Kích thước tập huấn luyện: {len(train_dataset)} mẫu\")\n",
    "        print(f\"Kích thước tập validation: {len(val_dataset)} mẫu\")\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=os.cpu_count() // 2 or 1)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=os.cpu_count() // 2 or 1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi tải dữ liệu thực: {e}. Sẽ dùng DummyDataset để tiếp tục.\")\n",
    "        train_dataset = DummySegmentationDataset(num_samples=100)\n",
    "        val_dataset = DummySegmentationDataset(num_samples=20)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "    # --- Khởi tạo Mô hình, Hàm mất mát, Bộ tối ưu hóa ---\n",
    "    model = SwinUNet(input_channels=3, num_classes=1).to(DEVICE)\n",
    "    criterion = CombinedLoss(bce_weight=0.5, dice_weight=0.5) # Có thể điều chỉnh trọng số\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(\"Bắt đầu huấn luyện mô hình...\")\n",
    "    training_history = train_model(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, DEVICE, CHECKPOINT_DIR)\n",
    "    print(\"Huấn luyện hoàn tất!\")\n",
    "\n",
    "    # --- Vẽ biểu đồ lịch sử huấn luyện ---\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_history['train_loss'], label='Train Loss')\n",
    "    plt.plot(training_history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss theo Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_history['val_dice'], label='Val Dice Coefficient')\n",
    "    plt.plot(training_history['val_iou'], label='Val IoU Score')\n",
    "    plt.title('Metrics theo Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
