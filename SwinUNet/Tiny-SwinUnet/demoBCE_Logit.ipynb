{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d6710d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import SwinConfig, SwinModel\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Sử dụng thiết bị: {DEVICE}\")\n",
    "\n",
    "# Thay đổi đường dẫn thư mục tùy theo máy của bạn\n",
    "train_img_dir = r'C:\\Users\\Admin\\Documents\\Python Project\\DPL Crack detection\\UDTIRI-Crack Detection\\train\\image'\n",
    "train_mask_dir = r'C:\\Users\\Admin\\Documents\\Python Project\\DPL Crack detection\\UDTIRI-Crack Detection\\train\\label'\n",
    "val_img_dir = r'C:\\Users\\Admin\\Documents\\Python Project\\DPL Crack detection\\UDTIRI-Crack Detection\\val\\image'\n",
    "val_mask_dir = r'C:\\Users\\Admin\\Documents\\Python Project\\DPL Crack detection\\UDTIRI-Crack Detection\\val\\label'\n",
    "\n",
    "# --- Thu thập đường dẫn tệp ảnh và mask ---\n",
    "train_img_paths = sorted([os.path.join(train_img_dir, f) for f in os.listdir(train_img_dir)])\n",
    "train_mask_paths = sorted([os.path.join(train_mask_dir, f) for f in os.listdir(train_mask_dir)])\n",
    "val_img_paths = sorted([os.path.join(val_img_dir, f) for f in os.listdir(val_img_dir)])\n",
    "val_mask_paths = sorted([os.path.join(val_mask_dir, f) for f in os.listdir(val_mask_dir)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrackDetectionDataset(Dataset):\n",
    "    def __init__(self, image_filenames, mask_filenames, augment=False):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.mask_filenames = mask_filenames\n",
    "        self.augment = augment\n",
    "\n",
    "        if len(self.image_filenames) != len(self.mask_filenames):\n",
    "            raise ValueError(\"Số lượng tệp ảnh và tệp mask không khớp.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    # Hàm thực hiện resize ảnh và mask về kích thước mong muốn (ban đầu)\n",
    "    def resize_image_and_mask(self, img, mask, target_size=IMG_SIZE):\n",
    "        img = cv2.resize(img, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (target_size, target_size), interpolation=cv2.INTER_NEAREST)\n",
    "        return img, mask\n",
    "\n",
    "    # Hàm thực hiện cắt ngẫu nhiên cho ảnh và mask\n",
    "    def random_crop_image_and_mask(self, img, mask, crop_size=IMG_SIZE, min_scale=0.7):\n",
    "        h, w = img.shape[:2]\n",
    "        current_min_dim = min(h, w)\n",
    "        crop_h = crop_w = int(random.uniform(min_scale, 1.0) * crop_size)\n",
    "\n",
    "        crop_h = min(crop_h, h)\n",
    "        crop_w = min(crop_w, w)\n",
    "\n",
    "        if h == crop_h and w == crop_w: # Không cần cắt nếu kích thước đã khớp\n",
    "            return img, mask\n",
    "\n",
    "        start_x = random.randint(0, w - crop_w)\n",
    "        start_y = random.randint(0, h - crop_h)\n",
    "\n",
    "        cropped_img = img[start_y:start_y + crop_h, start_x:start_x + crop_w]\n",
    "        cropped_mask = mask[start_y:start_y + crop_h, start_x:start_x + crop_w]\n",
    "        \n",
    "        # Resize lại về kích thước IMG_SIZE sau khi cắt\n",
    "        cropped_img = cv2.resize(cropped_img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        cropped_mask = cv2.resize(cropped_mask, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        return cropped_img, cropped_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.image_filenames[idx])\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Không thể đọc tệp ảnh: {self.image_filenames[idx]}\")\n",
    "\n",
    "        mask = cv2.imread(self.mask_filenames[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise ValueError(f\"Không thể đọc tệp mask: {self.mask_filenames[idx]}\")\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.augment:\n",
    "            if img.shape[0] < IMG_SIZE or img.shape[1] < IMG_SIZE:\n",
    "                img, mask = self.resize_image_and_mask(img, mask, target_size=IMG_SIZE)\n",
    "            \n",
    "            img, mask = self.random_crop_image_and_mask(img, mask, crop_size=IMG_SIZE, min_scale=0.7)\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                img = cv2.flip(img, 1)\n",
    "                mask = cv2.flip(mask, 1)\n",
    "            if random.random() < 0.5:\n",
    "                img = cv2.flip(img, 0)\n",
    "                mask = cv2.flip(mask, 0)\n",
    "        else:\n",
    "            img, mask = self.resize_image_and_mask(img, mask, target_size=IMG_SIZE)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        mask = mask.astype(np.float32) / 255.0\n",
    "        \n",
    "        if mask.ndim == 2:\n",
    "            mask = np.expand_dims(mask, axis=0) \n",
    "        elif mask.ndim == 3 and mask.shape[0] != 1:\n",
    "            if mask.shape[0] == 3:\n",
    "                mask = mask[0:1, :, :]\n",
    "            else:\n",
    "                raise ValueError(f\"Mask có hình dạng không mong muốn {mask.shape} tại chỉ số {idx} sau khi biến đổi. Expected channel dim 1.\")\n",
    "        \n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1)\n",
    "        mask_tensor = torch.from_numpy(mask)\n",
    "\n",
    "        return img_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d055257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, skip_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1) \n",
    "        )\n",
    "        \n",
    "        self.conv_block = ConvBlock(out_channels + skip_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, skip_features=None):\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        if skip_features is not None:\n",
    "            if x.shape[2:] != skip_features.shape[2:]:\n",
    "                x = nn.functional.interpolate(x, size=skip_features.shape[2:], mode='bilinear', align_corners=True)\n",
    "            \n",
    "            x = torch.cat([x, skip_features], dim=1)\n",
    "        \n",
    "        x = self.conv_block(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a01c7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SwinUNet(nn.Module):\n",
    "    def __init__(self, input_channels=3, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.IMG_SIZE = IMG_SIZE\n",
    "\n",
    "        config = SwinConfig(image_size=self.IMG_SIZE, num_channels=input_channels, \n",
    "                            patch_size=4, embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                            window_size=7, mlp_ratio=4., qkv_bias=True, hidden_dropout_prob=0.0, \n",
    "                            attention_probs_dropout_prob=0.0, drop_path_rate=0.1, \n",
    "                            hidden_act=\"gelu\", use_absolute_embeddings=False, \n",
    "                            patch_norm=True, initializer_range=0.02, layer_norm_eps=1e-05,\n",
    "                            out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"])\n",
    "        self.swin = SwinModel(config)\n",
    "\n",
    "        self.bottleneck = ConvBlock(config.embed_dim * 8, config.embed_dim * 8)\n",
    "\n",
    "        self.decoder4 = DecoderBlock(in_channels=config.embed_dim * 8, skip_channels=config.embed_dim * 4, out_channels=config.embed_dim * 4)\n",
    "        self.decoder3 = DecoderBlock(in_channels=config.embed_dim * 4, skip_channels=config.embed_dim * 2, out_channels=config.embed_dim * 2)\n",
    "        self.decoder2 = DecoderBlock(in_channels=config.embed_dim * 2, skip_channels=config.embed_dim * 1, out_channels=config.embed_dim * 1)\n",
    "        \n",
    "        self.decoder1 = DecoderBlock(in_channels=config.embed_dim * 1, skip_channels=0, out_channels=config.embed_dim // 2)\n",
    "\n",
    "        self.final_upsample = DecoderBlock(in_channels=config.embed_dim // 2, skip_channels=0, out_channels=config.embed_dim // 4)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(config.embed_dim // 4, num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.swin(pixel_values=x, output_hidden_states=True)\n",
    "        encoder_features = []\n",
    "\n",
    "        hs0 = outputs.hidden_states[0]\n",
    "        batch_size, num_patches, embed_dim = hs0.shape\n",
    "        side = int(np.sqrt(num_patches))\n",
    "        encoder_features.append(hs0.permute(0, 2, 1).reshape(batch_size, embed_dim, side, side))\n",
    "\n",
    "        hs1 = outputs.hidden_states[1]\n",
    "        batch_size, num_patches, embed_dim = hs1.shape\n",
    "        side = int(np.sqrt(num_patches))\n",
    "        encoder_features.append(hs1.permute(0, 2, 1).reshape(batch_size, embed_dim, side, side))\n",
    "\n",
    "        hs2 = outputs.hidden_states[2]\n",
    "        batch_size, num_patches, embed_dim = hs2.shape\n",
    "        side = int(np.sqrt(num_patches))\n",
    "        encoder_features.append(hs2.permute(0, 2, 1).reshape(batch_size, embed_dim, side, side))\n",
    "\n",
    "        x_bottleneck = outputs.hidden_states[4]\n",
    "        batch_size, num_patches, embed_dim = x_bottleneck.shape\n",
    "        side = int(np.sqrt(num_patches))\n",
    "        x_bottleneck = x_bottleneck.permute(0, 2, 1).reshape(batch_size, embed_dim, side, side)\n",
    "        \n",
    "        x = self.bottleneck(x_bottleneck)\n",
    "\n",
    "        x = self.decoder4(x, encoder_features[2])\n",
    "        x = self.decoder3(x, encoder_features[1])\n",
    "        x = self.decoder2(x, encoder_features[0])\n",
    "        x = self.decoder1(x)\n",
    "        x = self.final_upsample(x)\n",
    "\n",
    "        outputs = self.final_conv(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f8c5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predicted_masks, true_masks, smooth=1e-6):\n",
    "    \n",
    "    intersection = (predicted_masks * true_masks).sum()\n",
    "    union = (predicted_masks + true_masks).sum() - intersection\n",
    "    \n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    dice = (2. * intersection + smooth) / ((predicted_masks.sum() + true_masks.sum()) + smooth)\n",
    "    f1_score = dice \n",
    "\n",
    "    return iou.item(), f1_score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b820ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs, callbacks_config, start_epoch=0, best_val_loss_so_far=float('inf')):\n",
    "    best_val_loss = best_val_loss_so_far \n",
    "    patience_counter = 0\n",
    "    model_checkpoint_path = callbacks_config.get('checkpoint_path', 'swin_unet_best_pytorch.pth')\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_iou = 0.0\n",
    "        running_f1 = 0.0\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} Bắt đầu...\")\n",
    "        for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "            images = images.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            predicted_masks = (outputs > 0.5).float()\n",
    "            \n",
    "            batch_iou, batch_f1 = calculate_metrics(predicted_masks, masks)\n",
    "            running_iou += batch_iou * images.size(0)\n",
    "            running_f1 += batch_f1 * images.size(0)\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_iou = running_iou / len(train_loader.dataset)\n",
    "        epoch_f1 = running_f1 / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1} Kết thúc - Mất mát Huấn luyện: {epoch_loss:.4f}, IoU Huấn luyện: {epoch_iou:.4f}, F1-Score Huấn luyện: {epoch_f1:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_iou = 0.0\n",
    "        val_f1 = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                masks = masks.to(DEVICE)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                predicted_masks = (outputs > 0.5).float()\n",
    "                \n",
    "                batch_iou, batch_f1 = calculate_metrics(predicted_masks, masks)\n",
    "                val_iou += batch_iou * images.size(0)\n",
    "                val_f1 += batch_f1 * images.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_iou /= len(val_loader.dataset)\n",
    "        val_f1 /= len(val_loader.dataset)\n",
    "        print(f\"Mất mát Xác thực: {val_loss:.4f}, IoU Xác thực: {val_iou:.4f}, F1-Score Xác thực: {val_f1:.4f}\")\n",
    "        scheduler.step(val_loss) \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Learning Rate hiện tại: {current_lr:.8f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            print(f\"Mất mát xác thực tốt nhất được cập nhật: {best_val_loss:.4f}. Lưu mô hình và trạng thái...\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "            }, model_checkpoint_path)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Mất mát xác thực không cải thiện. Sự kiên nhẫn: {patience_counter}/{callbacks_config['patience']}\")\n",
    "            if patience_counter >= callbacks_config['patience']:\n",
    "                print(\"Dừng sớm!\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dec938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tính toán pos_weight từ 1500 tệp mask trong 'C:\\Users\\Admin\\Documents\\Python Project\\DPL Crack detection\\UDTIRI-Crack Detection\\train\\label'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đang xử lý mask: 100%|██████████| 1500/1500 [00:00<00:00, 2304.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số pixel được phân tích: 153600000\n",
      "Tổng số pixel vết nứt (dương): 4430132\n",
      "Tổng số pixel nền (âm): 149169868\n",
      "\n",
      "Giá trị pos_weight được tính toán: 33.6717\n",
      "\n",
      "Criterion được khởi tạo với pos_weight: 33.671653747558594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_pos_weight_from_masks(mask_dir, device):\n",
    "\n",
    "    total_pixels = 0\n",
    "    total_positive_pixels = 0\n",
    "    \n",
    "    mask_files = [f for f in os.listdir(mask_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "    \n",
    "    if not mask_files:\n",
    "        print(f\"Cảnh báo: Không tìm thấy tệp mask nào trong thư mục '{mask_dir}'.\")\n",
    "        print(\"Sử dụng pos_weight mặc định 1.0. Vui lòng kiểm tra đường dẫn và định dạng tệp.\")\n",
    "        return torch.tensor(1.0, dtype=torch.float).to(device)\n",
    "\n",
    "    print(f\"Đang tính toán pos_weight từ {len(mask_files)} tệp mask trong '{mask_dir}'...\")\n",
    "\n",
    "    for filename in tqdm(mask_files, desc=\"Đang xử lý mask\"):\n",
    "        mask_path = os.path.join(mask_dir, filename)\n",
    "\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if mask is None:\n",
    "            print(f\"Cảnh báo: Không thể đọc tệp mask: {mask_path}. Bỏ qua.\")\n",
    "            continue\n",
    "            \n",
    "        binary_mask = (mask > 127).astype(np.float32) \n",
    "        \n",
    "        total_pixels += binary_mask.size\n",
    "        total_positive_pixels += np.sum(binary_mask == 1)\n",
    "\n",
    "    total_negative_pixels = total_pixels - total_positive_pixels\n",
    "    \n",
    "    if total_positive_pixels == 0:\n",
    "        print(\"Cảnh báo: Không tìm thấy pixel dương nào (vết nứt) trong toàn bộ mask.\")\n",
    "        print(\"Mô hình sẽ không thể học được lớp vết nứt. Đang đặt pos_weight rất cao để cảnh báo hoặc cần kiểm tra dữ liệu.\")\n",
    "        return torch.tensor(1000.0, dtype=torch.float).to(device)\n",
    "\n",
    "    pos_weight = total_negative_pixels / total_positive_pixels\n",
    "    \n",
    "    print(f\"Tổng số pixel được phân tích: {total_pixels}\")\n",
    "    print(f\"Tổng số pixel vết nứt (dương): {total_positive_pixels}\")\n",
    "    print(f\"Tổng số pixel nền (âm): {total_negative_pixels}\")\n",
    "    print(f\"\\nGiá trị pos_weight được tính toán: {pos_weight:.4f}\")\n",
    "    \n",
    "    return torch.tensor(pos_weight, dtype=torch.float).to(device)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MASK_DIRECTORY = r\"C:\\Users\\Admin\\Documents\\Python Project\\DPL Crack detection\\UDTIRI-Crack Detection\\train\\label\" \n",
    "\n",
    "calculated_pos_weight_tensor = calculate_pos_weight_from_masks(MASK_DIRECTORY, DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=calculated_pos_weight_tensor)\n",
    "\n",
    "print(f\"\\nCriterion được khởi tạo với pos_weight: {criterion.pos_weight.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d09af99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinUNet(\n",
      "  (swin): SwinModel(\n",
      "    (embeddings): SwinEmbeddings(\n",
      "      (patch_embeddings): SwinPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      )\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): SwinEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): Identity()\n",
      "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.00909090880304575)\n",
      "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.0181818176060915)\n",
      "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.027272727340459824)\n",
      "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.036363635212183)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.045454543083906174)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.054545458406209946)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.06363636255264282)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.0727272778749466)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.08181818574666977)\n",
      "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SwinPatchMerging(\n",
      "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinStage(\n",
      "          (blocks): ModuleList(\n",
      "            (0): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.09090909361839294)\n",
      "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): SwinLayer(\n",
      "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attention): SwinAttention(\n",
      "                (self): SwinSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (output): SwinSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (drop_path): SwinDropPath(p=0.10000000149011612)\n",
      "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (intermediate): SwinIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): SwinOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
      "  )\n",
      "  (bottleneck): ConvBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder4): DecoderBlock(\n",
      "    (upsample): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (1): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (conv_block): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder3): DecoderBlock(\n",
      "    (upsample): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (conv_block): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder2): DecoderBlock(\n",
      "    (upsample): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (conv_block): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder1): DecoderBlock(\n",
      "    (upsample): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (conv_block): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_upsample): DecoderBlock(\n",
      "    (upsample): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "      (1): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (conv_block): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv2d(24, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Không tìm thấy checkpoint. Bắt đầu huấn luyện từ đầu (Epoch 0).\n",
      "\n",
      "Bắt đầu huấn luyện mô hình Swin-Unet...\n",
      "Epoch 1/10000 Bắt đầu...\n",
      "Epoch 1/10000, Batch 10/188, Loss: 0.7869\n",
      "Epoch 1/10000, Batch 20/188, Loss: 0.7634\n",
      "Epoch 1/10000, Batch 30/188, Loss: 0.7751\n",
      "Epoch 1/10000, Batch 40/188, Loss: 0.7762\n",
      "Epoch 1/10000, Batch 50/188, Loss: 0.8364\n",
      "Epoch 1/10000, Batch 60/188, Loss: 0.7711\n",
      "Epoch 1/10000, Batch 70/188, Loss: 0.6696\n",
      "Epoch 1/10000, Batch 80/188, Loss: 0.6424\n",
      "Epoch 1/10000, Batch 90/188, Loss: 0.6932\n",
      "Epoch 1/10000, Batch 100/188, Loss: 0.6722\n",
      "Epoch 1/10000, Batch 110/188, Loss: 0.6198\n",
      "Epoch 1/10000, Batch 120/188, Loss: 0.7296\n",
      "Epoch 1/10000, Batch 130/188, Loss: 0.5229\n",
      "Epoch 1/10000, Batch 140/188, Loss: 0.7809\n",
      "Epoch 1/10000, Batch 150/188, Loss: 0.6819\n",
      "Epoch 1/10000, Batch 160/188, Loss: 0.5947\n",
      "Epoch 1/10000, Batch 170/188, Loss: 0.5899\n",
      "Epoch 1/10000, Batch 180/188, Loss: 0.5842\n",
      "Epoch 1 Kết thúc - Mất mát Huấn luyện: 0.6798, IoU Huấn luyện: 0.3100, F1-Score Huấn luyện: 0.4569\n",
      "Mất mát Xác thực: 0.6698, IoU Xác thực: 0.2044, F1-Score Xác thực: 0.3144\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.6698. Lưu mô hình và trạng thái...\n",
      "Epoch 2/10000 Bắt đầu...\n",
      "Epoch 2/10000, Batch 10/188, Loss: 0.6146\n",
      "Epoch 2/10000, Batch 20/188, Loss: 0.6553\n",
      "Epoch 2/10000, Batch 30/188, Loss: 0.7164\n",
      "Epoch 2/10000, Batch 40/188, Loss: 0.6633\n",
      "Epoch 2/10000, Batch 50/188, Loss: 0.6728\n",
      "Epoch 2/10000, Batch 60/188, Loss: 0.4830\n",
      "Epoch 2/10000, Batch 70/188, Loss: 0.5333\n",
      "Epoch 2/10000, Batch 80/188, Loss: 0.4909\n",
      "Epoch 2/10000, Batch 90/188, Loss: 0.4930\n",
      "Epoch 2/10000, Batch 100/188, Loss: 0.5003\n",
      "Epoch 2/10000, Batch 110/188, Loss: 0.4721\n",
      "Epoch 2/10000, Batch 120/188, Loss: 0.4989\n",
      "Epoch 2/10000, Batch 130/188, Loss: 0.4959\n",
      "Epoch 2/10000, Batch 140/188, Loss: 0.4848\n",
      "Epoch 2/10000, Batch 150/188, Loss: 0.5427\n",
      "Epoch 2/10000, Batch 160/188, Loss: 0.5379\n",
      "Epoch 2/10000, Batch 170/188, Loss: 0.4890\n",
      "Epoch 2/10000, Batch 180/188, Loss: 0.5454\n",
      "Epoch 2 Kết thúc - Mất mát Huấn luyện: 0.5526, IoU Huấn luyện: 0.3784, F1-Score Huấn luyện: 0.5383\n",
      "Mất mát Xác thực: 0.5264, IoU Xác thực: 0.2462, F1-Score Xác thực: 0.3716\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.5264. Lưu mô hình và trạng thái...\n",
      "Epoch 3/10000 Bắt đầu...\n",
      "Epoch 3/10000, Batch 10/188, Loss: 0.4761\n",
      "Epoch 3/10000, Batch 20/188, Loss: 0.6828\n",
      "Epoch 3/10000, Batch 30/188, Loss: 0.5492\n",
      "Epoch 3/10000, Batch 40/188, Loss: 0.5261\n",
      "Epoch 3/10000, Batch 50/188, Loss: 0.5518\n",
      "Epoch 3/10000, Batch 60/188, Loss: 0.5203\n",
      "Epoch 3/10000, Batch 70/188, Loss: 0.4341\n",
      "Epoch 3/10000, Batch 80/188, Loss: 0.4631\n",
      "Epoch 3/10000, Batch 90/188, Loss: 0.4902\n",
      "Epoch 3/10000, Batch 100/188, Loss: 0.4995\n",
      "Epoch 3/10000, Batch 110/188, Loss: 0.4981\n",
      "Epoch 3/10000, Batch 120/188, Loss: 0.4916\n",
      "Epoch 3/10000, Batch 130/188, Loss: 0.4466\n",
      "Epoch 3/10000, Batch 140/188, Loss: 0.4207\n",
      "Epoch 3/10000, Batch 150/188, Loss: 0.5350\n",
      "Epoch 3/10000, Batch 160/188, Loss: 0.4555\n",
      "Epoch 3/10000, Batch 170/188, Loss: 0.4759\n",
      "Epoch 3/10000, Batch 180/188, Loss: 0.4061\n",
      "Epoch 3 Kết thúc - Mất mát Huấn luyện: 0.4900, IoU Huấn luyện: 0.4026, F1-Score Huấn luyện: 0.5639\n",
      "Mất mát Xác thực: 0.4754, IoU Xác thực: 0.2855, F1-Score Xác thực: 0.4073\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.4754. Lưu mô hình và trạng thái...\n",
      "Epoch 4/10000 Bắt đầu...\n",
      "Epoch 4/10000, Batch 10/188, Loss: 0.4082\n",
      "Epoch 4/10000, Batch 20/188, Loss: 0.5066\n",
      "Epoch 4/10000, Batch 30/188, Loss: 0.4124\n",
      "Epoch 4/10000, Batch 40/188, Loss: 0.4471\n",
      "Epoch 4/10000, Batch 50/188, Loss: 0.4573\n",
      "Epoch 4/10000, Batch 60/188, Loss: 0.4781\n",
      "Epoch 4/10000, Batch 70/188, Loss: 0.4003\n",
      "Epoch 4/10000, Batch 80/188, Loss: 0.4956\n",
      "Epoch 4/10000, Batch 90/188, Loss: 0.5953\n",
      "Epoch 4/10000, Batch 100/188, Loss: 0.4613\n",
      "Epoch 4/10000, Batch 110/188, Loss: 0.4027\n",
      "Epoch 4/10000, Batch 120/188, Loss: 0.4456\n",
      "Epoch 4/10000, Batch 130/188, Loss: 0.4279\n",
      "Epoch 4/10000, Batch 140/188, Loss: 0.4193\n",
      "Epoch 4/10000, Batch 150/188, Loss: 0.4339\n",
      "Epoch 4/10000, Batch 160/188, Loss: 0.4077\n",
      "Epoch 4/10000, Batch 170/188, Loss: 0.4265\n",
      "Epoch 4/10000, Batch 180/188, Loss: 0.4634\n",
      "Epoch 4 Kết thúc - Mất mát Huấn luyện: 0.4389, IoU Huấn luyện: 0.4156, F1-Score Huấn luyện: 0.5766\n",
      "Mất mát Xác thực: 0.4322, IoU Xác thực: 0.2637, F1-Score Xác thực: 0.3906\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.4322. Lưu mô hình và trạng thái...\n",
      "Epoch 5/10000 Bắt đầu...\n",
      "Epoch 5/10000, Batch 10/188, Loss: 0.4216\n",
      "Epoch 5/10000, Batch 20/188, Loss: 0.3992\n",
      "Epoch 5/10000, Batch 30/188, Loss: 0.3590\n",
      "Epoch 5/10000, Batch 40/188, Loss: 0.4029\n",
      "Epoch 5/10000, Batch 50/188, Loss: 0.3780\n",
      "Epoch 5/10000, Batch 60/188, Loss: 0.4479\n",
      "Epoch 5/10000, Batch 70/188, Loss: 0.3674\n",
      "Epoch 5/10000, Batch 80/188, Loss: 0.4200\n",
      "Epoch 5/10000, Batch 90/188, Loss: 0.3955\n",
      "Epoch 5/10000, Batch 100/188, Loss: 0.3433\n",
      "Epoch 5/10000, Batch 110/188, Loss: 0.3784\n",
      "Epoch 5/10000, Batch 120/188, Loss: 0.3352\n",
      "Epoch 5/10000, Batch 130/188, Loss: 0.4355\n",
      "Epoch 5/10000, Batch 140/188, Loss: 0.4425\n",
      "Epoch 5/10000, Batch 150/188, Loss: 0.3514\n",
      "Epoch 5/10000, Batch 160/188, Loss: 0.3797\n",
      "Epoch 5/10000, Batch 170/188, Loss: 0.3396\n",
      "Epoch 5/10000, Batch 180/188, Loss: 0.3716\n",
      "Epoch 5 Kết thúc - Mất mát Huấn luyện: 0.3984, IoU Huấn luyện: 0.4274, F1-Score Huấn luyện: 0.5890\n",
      "Mất mát Xác thực: 0.3807, IoU Xác thực: 0.3002, F1-Score Xác thực: 0.4322\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.3807. Lưu mô hình và trạng thái...\n",
      "Epoch 6/10000 Bắt đầu...\n",
      "Epoch 6/10000, Batch 10/188, Loss: 0.4684\n",
      "Epoch 6/10000, Batch 20/188, Loss: 0.3909\n",
      "Epoch 6/10000, Batch 30/188, Loss: 0.4432\n",
      "Epoch 6/10000, Batch 40/188, Loss: 0.4177\n",
      "Epoch 6/10000, Batch 50/188, Loss: 0.3587\n",
      "Epoch 6/10000, Batch 60/188, Loss: 0.3563\n",
      "Epoch 6/10000, Batch 70/188, Loss: 0.5421\n",
      "Epoch 6/10000, Batch 80/188, Loss: 0.3508\n",
      "Epoch 6/10000, Batch 90/188, Loss: 0.3497\n",
      "Epoch 6/10000, Batch 100/188, Loss: 0.3365\n",
      "Epoch 6/10000, Batch 110/188, Loss: 0.2841\n",
      "Epoch 6/10000, Batch 120/188, Loss: 0.3474\n",
      "Epoch 6/10000, Batch 130/188, Loss: 0.3853\n",
      "Epoch 6/10000, Batch 140/188, Loss: 0.4568\n",
      "Epoch 6/10000, Batch 150/188, Loss: 0.3947\n",
      "Epoch 6/10000, Batch 160/188, Loss: 0.3370\n",
      "Epoch 6/10000, Batch 170/188, Loss: 0.2912\n",
      "Epoch 6/10000, Batch 180/188, Loss: 0.3357\n",
      "Epoch 6 Kết thúc - Mất mát Huấn luyện: 0.3641, IoU Huấn luyện: 0.4325, F1-Score Huấn luyện: 0.5940\n",
      "Mất mát Xác thực: 0.3564, IoU Xác thực: 0.3291, F1-Score Xác thực: 0.4545\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.3564. Lưu mô hình và trạng thái...\n",
      "Epoch 7/10000 Bắt đầu...\n",
      "Epoch 7/10000, Batch 10/188, Loss: 0.3245\n",
      "Epoch 7/10000, Batch 20/188, Loss: 0.2840\n",
      "Epoch 7/10000, Batch 30/188, Loss: 0.3015\n",
      "Epoch 7/10000, Batch 40/188, Loss: 0.3250\n",
      "Epoch 7/10000, Batch 50/188, Loss: 0.2982\n",
      "Epoch 7/10000, Batch 60/188, Loss: 0.3289\n",
      "Epoch 7/10000, Batch 70/188, Loss: 0.3789\n",
      "Epoch 7/10000, Batch 80/188, Loss: 0.2800\n",
      "Epoch 7/10000, Batch 90/188, Loss: 0.3442\n",
      "Epoch 7/10000, Batch 100/188, Loss: 0.3526\n",
      "Epoch 7/10000, Batch 110/188, Loss: 0.5230\n",
      "Epoch 7/10000, Batch 120/188, Loss: 0.3247\n",
      "Epoch 7/10000, Batch 130/188, Loss: 0.2975\n",
      "Epoch 7/10000, Batch 140/188, Loss: 0.3474\n",
      "Epoch 7/10000, Batch 150/188, Loss: 0.3194\n",
      "Epoch 7/10000, Batch 160/188, Loss: 0.3593\n",
      "Epoch 7/10000, Batch 170/188, Loss: 0.3051\n",
      "Epoch 7/10000, Batch 180/188, Loss: 0.3048\n",
      "Epoch 7 Kết thúc - Mất mát Huấn luyện: 0.3346, IoU Huấn luyện: 0.4399, F1-Score Huấn luyện: 0.6025\n",
      "Mất mát Xác thực: 0.3260, IoU Xác thực: 0.3193, F1-Score Xác thực: 0.4540\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.3260. Lưu mô hình và trạng thái...\n",
      "Epoch 8/10000 Bắt đầu...\n",
      "Epoch 8/10000, Batch 10/188, Loss: 0.3067\n",
      "Epoch 8/10000, Batch 20/188, Loss: 0.3071\n",
      "Epoch 8/10000, Batch 30/188, Loss: 0.2856\n",
      "Epoch 8/10000, Batch 40/188, Loss: 0.2738\n",
      "Epoch 8/10000, Batch 50/188, Loss: 0.3137\n",
      "Epoch 8/10000, Batch 60/188, Loss: 0.2504\n",
      "Epoch 8/10000, Batch 70/188, Loss: 0.2698\n",
      "Epoch 8/10000, Batch 80/188, Loss: 0.3333\n",
      "Epoch 8/10000, Batch 90/188, Loss: 0.3185\n",
      "Epoch 8/10000, Batch 100/188, Loss: 0.3658\n",
      "Epoch 8/10000, Batch 110/188, Loss: 0.2474\n",
      "Epoch 8/10000, Batch 120/188, Loss: 0.2657\n",
      "Epoch 8/10000, Batch 130/188, Loss: 0.2880\n",
      "Epoch 8/10000, Batch 140/188, Loss: 0.3234\n",
      "Epoch 8/10000, Batch 150/188, Loss: 0.2580\n",
      "Epoch 8/10000, Batch 160/188, Loss: 0.3401\n",
      "Epoch 8/10000, Batch 170/188, Loss: 0.2987\n",
      "Epoch 8/10000, Batch 180/188, Loss: 0.3093\n",
      "Epoch 8 Kết thúc - Mất mát Huấn luyện: 0.3160, IoU Huấn luyện: 0.4448, F1-Score Huấn luyện: 0.6066\n",
      "Mất mát Xác thực: 0.3041, IoU Xác thực: 0.3077, F1-Score Xác thực: 0.4430\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.3041. Lưu mô hình và trạng thái...\n",
      "Epoch 9/10000 Bắt đầu...\n",
      "Epoch 9/10000, Batch 10/188, Loss: 0.2308\n",
      "Epoch 9/10000, Batch 20/188, Loss: 0.3341\n",
      "Epoch 9/10000, Batch 30/188, Loss: 0.3364\n",
      "Epoch 9/10000, Batch 40/188, Loss: 0.4358\n",
      "Epoch 9/10000, Batch 50/188, Loss: 0.2299\n",
      "Epoch 9/10000, Batch 60/188, Loss: 0.2595\n",
      "Epoch 9/10000, Batch 70/188, Loss: 0.2857\n",
      "Epoch 9/10000, Batch 80/188, Loss: 0.3624\n",
      "Epoch 9/10000, Batch 90/188, Loss: 0.2761\n",
      "Epoch 9/10000, Batch 100/188, Loss: 0.3391\n",
      "Epoch 9/10000, Batch 110/188, Loss: 0.2703\n",
      "Epoch 9/10000, Batch 120/188, Loss: 0.2546\n",
      "Epoch 9/10000, Batch 130/188, Loss: 0.3374\n",
      "Epoch 9/10000, Batch 140/188, Loss: 0.2654\n",
      "Epoch 9/10000, Batch 150/188, Loss: 0.4502\n",
      "Epoch 9/10000, Batch 160/188, Loss: 0.3087\n",
      "Epoch 9/10000, Batch 170/188, Loss: 0.2969\n",
      "Epoch 9/10000, Batch 180/188, Loss: 0.2855\n",
      "Epoch 9 Kết thúc - Mất mát Huấn luyện: 0.2987, IoU Huấn luyện: 0.4393, F1-Score Huấn luyện: 0.5997\n",
      "Mất mát Xác thực: 0.2939, IoU Xác thực: 0.3205, F1-Score Xác thực: 0.4535\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2939. Lưu mô hình và trạng thái...\n",
      "Epoch 10/10000 Bắt đầu...\n",
      "Epoch 10/10000, Batch 10/188, Loss: 0.2357\n",
      "Epoch 10/10000, Batch 20/188, Loss: 0.2977\n",
      "Epoch 10/10000, Batch 30/188, Loss: 0.5079\n",
      "Epoch 10/10000, Batch 40/188, Loss: 0.2349\n",
      "Epoch 10/10000, Batch 50/188, Loss: 0.4469\n",
      "Epoch 10/10000, Batch 60/188, Loss: 0.2284\n",
      "Epoch 10/10000, Batch 70/188, Loss: 0.2051\n",
      "Epoch 10/10000, Batch 80/188, Loss: 0.4305\n",
      "Epoch 10/10000, Batch 90/188, Loss: 0.2280\n",
      "Epoch 10/10000, Batch 100/188, Loss: 0.2415\n",
      "Epoch 10/10000, Batch 110/188, Loss: 0.2304\n",
      "Epoch 10/10000, Batch 120/188, Loss: 0.2824\n",
      "Epoch 10/10000, Batch 130/188, Loss: 0.2399\n",
      "Epoch 10/10000, Batch 140/188, Loss: 0.3615\n",
      "Epoch 10/10000, Batch 150/188, Loss: 0.2716\n",
      "Epoch 10/10000, Batch 160/188, Loss: 0.2517\n",
      "Epoch 10/10000, Batch 170/188, Loss: 0.2345\n",
      "Epoch 10/10000, Batch 180/188, Loss: 0.2483\n",
      "Epoch 10 Kết thúc - Mất mát Huấn luyện: 0.2803, IoU Huấn luyện: 0.4481, F1-Score Huấn luyện: 0.6100\n",
      "Mất mát Xác thực: 0.2911, IoU Xác thực: 0.3023, F1-Score Xác thực: 0.4359\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2911. Lưu mô hình và trạng thái...\n",
      "Epoch 11/10000 Bắt đầu...\n",
      "Epoch 11/10000, Batch 10/188, Loss: 0.2459\n",
      "Epoch 11/10000, Batch 20/188, Loss: 0.2237\n",
      "Epoch 11/10000, Batch 30/188, Loss: 0.2580\n",
      "Epoch 11/10000, Batch 40/188, Loss: 0.2080\n",
      "Epoch 11/10000, Batch 50/188, Loss: 0.2170\n",
      "Epoch 11/10000, Batch 60/188, Loss: 0.2149\n",
      "Epoch 11/10000, Batch 70/188, Loss: 0.2243\n",
      "Epoch 11/10000, Batch 80/188, Loss: 0.2634\n",
      "Epoch 11/10000, Batch 90/188, Loss: 0.2030\n",
      "Epoch 11/10000, Batch 100/188, Loss: 0.2880\n",
      "Epoch 11/10000, Batch 110/188, Loss: 0.3081\n",
      "Epoch 11/10000, Batch 120/188, Loss: 0.2773\n",
      "Epoch 11/10000, Batch 130/188, Loss: 0.2588\n",
      "Epoch 11/10000, Batch 140/188, Loss: 0.2803\n",
      "Epoch 11/10000, Batch 150/188, Loss: 0.2026\n",
      "Epoch 11/10000, Batch 160/188, Loss: 0.2624\n",
      "Epoch 11/10000, Batch 170/188, Loss: 0.2460\n",
      "Epoch 11/10000, Batch 180/188, Loss: 0.3526\n",
      "Epoch 11 Kết thúc - Mất mát Huấn luyện: 0.2740, IoU Huấn luyện: 0.4466, F1-Score Huấn luyện: 0.6074\n",
      "Mất mát Xác thực: 0.3429, IoU Xác thực: 0.2597, F1-Score Xác thực: 0.3871\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 12/10000 Bắt đầu...\n",
      "Epoch 12/10000, Batch 10/188, Loss: 0.2808\n",
      "Epoch 12/10000, Batch 20/188, Loss: 0.3212\n",
      "Epoch 12/10000, Batch 30/188, Loss: 0.1956\n",
      "Epoch 12/10000, Batch 40/188, Loss: 0.2121\n",
      "Epoch 12/10000, Batch 50/188, Loss: 0.2141\n",
      "Epoch 12/10000, Batch 60/188, Loss: 0.2056\n",
      "Epoch 12/10000, Batch 70/188, Loss: 0.2316\n",
      "Epoch 12/10000, Batch 80/188, Loss: 0.4075\n",
      "Epoch 12/10000, Batch 90/188, Loss: 0.2144\n",
      "Epoch 12/10000, Batch 100/188, Loss: 0.2156\n",
      "Epoch 12/10000, Batch 110/188, Loss: 0.2402\n",
      "Epoch 12/10000, Batch 120/188, Loss: 0.3359\n",
      "Epoch 12/10000, Batch 130/188, Loss: 0.1644\n",
      "Epoch 12/10000, Batch 140/188, Loss: 0.1929\n",
      "Epoch 12/10000, Batch 150/188, Loss: 0.2603\n",
      "Epoch 12/10000, Batch 160/188, Loss: 0.2143\n",
      "Epoch 12/10000, Batch 170/188, Loss: 0.2028\n",
      "Epoch 12/10000, Batch 180/188, Loss: 0.2643\n",
      "Epoch 12 Kết thúc - Mất mát Huấn luyện: 0.2530, IoU Huấn luyện: 0.4570, F1-Score Huấn luyện: 0.6188\n",
      "Mất mát Xác thực: 0.2550, IoU Xác thực: 0.3407, F1-Score Xác thực: 0.4785\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2550. Lưu mô hình và trạng thái...\n",
      "Epoch 13/10000 Bắt đầu...\n",
      "Epoch 13/10000, Batch 10/188, Loss: 0.2369\n",
      "Epoch 13/10000, Batch 20/188, Loss: 0.2434\n",
      "Epoch 13/10000, Batch 30/188, Loss: 0.2534\n",
      "Epoch 13/10000, Batch 40/188, Loss: 0.2515\n",
      "Epoch 13/10000, Batch 50/188, Loss: 0.1984\n",
      "Epoch 13/10000, Batch 60/188, Loss: 0.2414\n",
      "Epoch 13/10000, Batch 70/188, Loss: 0.3640\n",
      "Epoch 13/10000, Batch 80/188, Loss: 0.1980\n",
      "Epoch 13/10000, Batch 90/188, Loss: 0.2154\n",
      "Epoch 13/10000, Batch 100/188, Loss: 0.2377\n",
      "Epoch 13/10000, Batch 110/188, Loss: 0.1969\n",
      "Epoch 13/10000, Batch 120/188, Loss: 0.2045\n",
      "Epoch 13/10000, Batch 130/188, Loss: 0.2168\n",
      "Epoch 13/10000, Batch 140/188, Loss: 0.4212\n",
      "Epoch 13/10000, Batch 150/188, Loss: 0.3015\n",
      "Epoch 13/10000, Batch 160/188, Loss: 0.2171\n",
      "Epoch 13/10000, Batch 170/188, Loss: 0.2040\n",
      "Epoch 13/10000, Batch 180/188, Loss: 0.3598\n",
      "Epoch 13 Kết thúc - Mất mát Huấn luyện: 0.2461, IoU Huấn luyện: 0.4611, F1-Score Huấn luyện: 0.6219\n",
      "Mất mát Xác thực: 0.2479, IoU Xác thực: 0.3280, F1-Score Xác thực: 0.4651\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2479. Lưu mô hình và trạng thái...\n",
      "Epoch 14/10000 Bắt đầu...\n",
      "Epoch 14/10000, Batch 10/188, Loss: 0.5073\n",
      "Epoch 14/10000, Batch 20/188, Loss: 0.2718\n",
      "Epoch 14/10000, Batch 30/188, Loss: 0.2142\n",
      "Epoch 14/10000, Batch 40/188, Loss: 0.1817\n",
      "Epoch 14/10000, Batch 50/188, Loss: 0.1739\n",
      "Epoch 14/10000, Batch 60/188, Loss: 0.2510\n",
      "Epoch 14/10000, Batch 70/188, Loss: 0.1995\n",
      "Epoch 14/10000, Batch 80/188, Loss: 0.4034\n",
      "Epoch 14/10000, Batch 90/188, Loss: 0.2340\n",
      "Epoch 14/10000, Batch 100/188, Loss: 0.1981\n",
      "Epoch 14/10000, Batch 110/188, Loss: 0.1951\n",
      "Epoch 14/10000, Batch 120/188, Loss: 0.2612\n",
      "Epoch 14/10000, Batch 130/188, Loss: 0.4397\n",
      "Epoch 14/10000, Batch 140/188, Loss: 0.1972\n",
      "Epoch 14/10000, Batch 150/188, Loss: 0.1653\n",
      "Epoch 14/10000, Batch 160/188, Loss: 0.1899\n",
      "Epoch 14/10000, Batch 170/188, Loss: 0.2268\n",
      "Epoch 14/10000, Batch 180/188, Loss: 0.3082\n",
      "Epoch 14 Kết thúc - Mất mát Huấn luyện: 0.2404, IoU Huấn luyện: 0.4570, F1-Score Huấn luyện: 0.6184\n",
      "Mất mát Xác thực: 0.2403, IoU Xác thực: 0.3217, F1-Score Xác thực: 0.4613\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2403. Lưu mô hình và trạng thái...\n",
      "Epoch 15/10000 Bắt đầu...\n",
      "Epoch 15/10000, Batch 10/188, Loss: 0.2225\n",
      "Epoch 15/10000, Batch 20/188, Loss: 0.3484\n",
      "Epoch 15/10000, Batch 30/188, Loss: 0.2101\n",
      "Epoch 15/10000, Batch 40/188, Loss: 0.2223\n",
      "Epoch 15/10000, Batch 50/188, Loss: 0.4787\n",
      "Epoch 15/10000, Batch 60/188, Loss: 0.2599\n",
      "Epoch 15/10000, Batch 70/188, Loss: 0.2264\n",
      "Epoch 15/10000, Batch 80/188, Loss: 0.2251\n",
      "Epoch 15/10000, Batch 90/188, Loss: 0.2047\n",
      "Epoch 15/10000, Batch 100/188, Loss: 0.2040\n",
      "Epoch 15/10000, Batch 110/188, Loss: 0.2057\n",
      "Epoch 15/10000, Batch 120/188, Loss: 0.3000\n",
      "Epoch 15/10000, Batch 130/188, Loss: 0.2076\n",
      "Epoch 15/10000, Batch 140/188, Loss: 0.2178\n",
      "Epoch 15/10000, Batch 150/188, Loss: 0.2814\n",
      "Epoch 15/10000, Batch 160/188, Loss: 0.2157\n",
      "Epoch 15/10000, Batch 170/188, Loss: 0.2049\n",
      "Epoch 15/10000, Batch 180/188, Loss: 0.1944\n",
      "Epoch 15 Kết thúc - Mất mát Huấn luyện: 0.2360, IoU Huấn luyện: 0.4508, F1-Score Huấn luyện: 0.6105\n",
      "Mất mát Xác thực: 0.2305, IoU Xác thực: 0.3323, F1-Score Xác thực: 0.4718\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2305. Lưu mô hình và trạng thái...\n",
      "Epoch 16/10000 Bắt đầu...\n",
      "Epoch 16/10000, Batch 10/188, Loss: 0.2699\n",
      "Epoch 16/10000, Batch 20/188, Loss: 0.1854\n",
      "Epoch 16/10000, Batch 30/188, Loss: 0.2237\n",
      "Epoch 16/10000, Batch 40/188, Loss: 0.2150\n",
      "Epoch 16/10000, Batch 50/188, Loss: 0.2293\n",
      "Epoch 16/10000, Batch 60/188, Loss: 0.2122\n",
      "Epoch 16/10000, Batch 70/188, Loss: 0.1481\n",
      "Epoch 16/10000, Batch 80/188, Loss: 0.2087\n",
      "Epoch 16/10000, Batch 90/188, Loss: 0.2304\n",
      "Epoch 16/10000, Batch 100/188, Loss: 0.2416\n",
      "Epoch 16/10000, Batch 110/188, Loss: 0.2129\n",
      "Epoch 16/10000, Batch 120/188, Loss: 0.1801\n",
      "Epoch 16/10000, Batch 130/188, Loss: 0.1246\n",
      "Epoch 16/10000, Batch 140/188, Loss: 0.1699\n",
      "Epoch 16/10000, Batch 150/188, Loss: 0.1532\n",
      "Epoch 16/10000, Batch 160/188, Loss: 0.3090\n",
      "Epoch 16/10000, Batch 170/188, Loss: 0.2344\n",
      "Epoch 16/10000, Batch 180/188, Loss: 0.2633\n",
      "Epoch 16 Kết thúc - Mất mát Huấn luyện: 0.2262, IoU Huấn luyện: 0.4596, F1-Score Huấn luyện: 0.6198\n",
      "Mất mát Xác thực: 0.2327, IoU Xác thực: 0.3438, F1-Score Xác thực: 0.4838\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 17/10000 Bắt đầu...\n",
      "Epoch 17/10000, Batch 10/188, Loss: 0.3167\n",
      "Epoch 17/10000, Batch 20/188, Loss: 0.1917\n",
      "Epoch 17/10000, Batch 30/188, Loss: 0.1927\n",
      "Epoch 17/10000, Batch 40/188, Loss: 0.2649\n",
      "Epoch 17/10000, Batch 50/188, Loss: 0.1784\n",
      "Epoch 17/10000, Batch 60/188, Loss: 0.4109\n",
      "Epoch 17/10000, Batch 70/188, Loss: 0.1893\n",
      "Epoch 17/10000, Batch 80/188, Loss: 0.2725\n",
      "Epoch 17/10000, Batch 90/188, Loss: 0.2823\n",
      "Epoch 17/10000, Batch 100/188, Loss: 0.3134\n",
      "Epoch 17/10000, Batch 110/188, Loss: 0.1733\n",
      "Epoch 17/10000, Batch 120/188, Loss: 0.2323\n",
      "Epoch 17/10000, Batch 130/188, Loss: 0.2855\n",
      "Epoch 17/10000, Batch 140/188, Loss: 0.1354\n",
      "Epoch 17/10000, Batch 150/188, Loss: 0.2775\n",
      "Epoch 17/10000, Batch 160/188, Loss: 0.2946\n",
      "Epoch 17/10000, Batch 170/188, Loss: 0.1897\n",
      "Epoch 17/10000, Batch 180/188, Loss: 0.2637\n",
      "Epoch 17 Kết thúc - Mất mát Huấn luyện: 0.2246, IoU Huấn luyện: 0.4635, F1-Score Huấn luyện: 0.6257\n",
      "Mất mát Xác thực: 0.2363, IoU Xác thực: 0.3085, F1-Score Xác thực: 0.4433\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 2/20\n",
      "Epoch 18/10000 Bắt đầu...\n",
      "Epoch 18/10000, Batch 10/188, Loss: 0.1624\n",
      "Epoch 18/10000, Batch 20/188, Loss: 0.3426\n",
      "Epoch 18/10000, Batch 30/188, Loss: 0.1840\n",
      "Epoch 18/10000, Batch 40/188, Loss: 0.1821\n",
      "Epoch 18/10000, Batch 50/188, Loss: 0.1415\n",
      "Epoch 18/10000, Batch 60/188, Loss: 0.2046\n",
      "Epoch 18/10000, Batch 70/188, Loss: 0.2580\n",
      "Epoch 18/10000, Batch 80/188, Loss: 0.2207\n",
      "Epoch 18/10000, Batch 90/188, Loss: 0.2469\n",
      "Epoch 18/10000, Batch 100/188, Loss: 0.1918\n",
      "Epoch 18/10000, Batch 110/188, Loss: 0.1752\n",
      "Epoch 18/10000, Batch 120/188, Loss: 0.6013\n",
      "Epoch 18/10000, Batch 130/188, Loss: 0.3423\n",
      "Epoch 18/10000, Batch 140/188, Loss: 0.2630\n",
      "Epoch 18/10000, Batch 150/188, Loss: 0.2558\n",
      "Epoch 18/10000, Batch 160/188, Loss: 0.1823\n",
      "Epoch 18/10000, Batch 170/188, Loss: 0.2138\n",
      "Epoch 18/10000, Batch 180/188, Loss: 0.2648\n",
      "Epoch 18 Kết thúc - Mất mát Huấn luyện: 0.2144, IoU Huấn luyện: 0.4717, F1-Score Huấn luyện: 0.6337\n",
      "Mất mát Xác thực: 0.2488, IoU Xác thực: 0.2804, F1-Score Xác thực: 0.4135\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 3/20\n",
      "Epoch 19/10000 Bắt đầu...\n",
      "Epoch 19/10000, Batch 10/188, Loss: 0.2545\n",
      "Epoch 19/10000, Batch 20/188, Loss: 0.2147\n",
      "Epoch 19/10000, Batch 30/188, Loss: 0.1781\n",
      "Epoch 19/10000, Batch 40/188, Loss: 0.2389\n",
      "Epoch 19/10000, Batch 50/188, Loss: 0.1546\n",
      "Epoch 19/10000, Batch 60/188, Loss: 0.1737\n",
      "Epoch 19/10000, Batch 70/188, Loss: 0.2161\n",
      "Epoch 19/10000, Batch 80/188, Loss: 0.1680\n",
      "Epoch 19/10000, Batch 90/188, Loss: 0.2269\n",
      "Epoch 19/10000, Batch 100/188, Loss: 0.1776\n",
      "Epoch 19/10000, Batch 110/188, Loss: 0.1994\n",
      "Epoch 19/10000, Batch 120/188, Loss: 0.1663\n",
      "Epoch 19/10000, Batch 130/188, Loss: 0.1972\n",
      "Epoch 19/10000, Batch 140/188, Loss: 0.2387\n",
      "Epoch 19/10000, Batch 150/188, Loss: 0.1854\n",
      "Epoch 19/10000, Batch 160/188, Loss: 0.3201\n",
      "Epoch 19/10000, Batch 170/188, Loss: 0.2811\n",
      "Epoch 19/10000, Batch 180/188, Loss: 0.1841\n",
      "Epoch 19 Kết thúc - Mất mát Huấn luyện: 0.2133, IoU Huấn luyện: 0.4691, F1-Score Huấn luyện: 0.6314\n",
      "Mất mát Xác thực: 0.2199, IoU Xác thực: 0.3353, F1-Score Xác thực: 0.4724\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2199. Lưu mô hình và trạng thái...\n",
      "Epoch 20/10000 Bắt đầu...\n",
      "Epoch 20/10000, Batch 10/188, Loss: 0.2372\n",
      "Epoch 20/10000, Batch 20/188, Loss: 0.1519\n",
      "Epoch 20/10000, Batch 30/188, Loss: 0.1718\n",
      "Epoch 20/10000, Batch 40/188, Loss: 0.2183\n",
      "Epoch 20/10000, Batch 50/188, Loss: 0.3123\n",
      "Epoch 20/10000, Batch 60/188, Loss: 0.1478\n",
      "Epoch 20/10000, Batch 70/188, Loss: 0.1900\n",
      "Epoch 20/10000, Batch 80/188, Loss: 0.2064\n",
      "Epoch 20/10000, Batch 90/188, Loss: 0.1424\n",
      "Epoch 20/10000, Batch 100/188, Loss: 0.2077\n",
      "Epoch 20/10000, Batch 110/188, Loss: 0.2771\n",
      "Epoch 20/10000, Batch 120/188, Loss: 0.3167\n",
      "Epoch 20/10000, Batch 130/188, Loss: 0.2254\n",
      "Epoch 20/10000, Batch 140/188, Loss: 0.1578\n",
      "Epoch 20/10000, Batch 150/188, Loss: 0.2992\n",
      "Epoch 20/10000, Batch 160/188, Loss: 0.2228\n",
      "Epoch 20/10000, Batch 170/188, Loss: 0.2088\n",
      "Epoch 20/10000, Batch 180/188, Loss: 0.1606\n",
      "Epoch 20 Kết thúc - Mất mát Huấn luyện: 0.2078, IoU Huấn luyện: 0.4668, F1-Score Huấn luyện: 0.6280\n",
      "Mất mát Xác thực: 0.2165, IoU Xác thực: 0.3242, F1-Score Xác thực: 0.4642\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2165. Lưu mô hình và trạng thái...\n",
      "Epoch 21/10000 Bắt đầu...\n",
      "Epoch 21/10000, Batch 10/188, Loss: 0.1226\n",
      "Epoch 21/10000, Batch 20/188, Loss: 0.1621\n",
      "Epoch 21/10000, Batch 30/188, Loss: 0.1935\n",
      "Epoch 21/10000, Batch 40/188, Loss: 0.2194\n",
      "Epoch 21/10000, Batch 50/188, Loss: 0.1849\n",
      "Epoch 21/10000, Batch 60/188, Loss: 0.2821\n",
      "Epoch 21/10000, Batch 70/188, Loss: 0.1799\n",
      "Epoch 21/10000, Batch 80/188, Loss: 0.2066\n",
      "Epoch 21/10000, Batch 90/188, Loss: 0.2552\n",
      "Epoch 21/10000, Batch 100/188, Loss: 0.1844\n",
      "Epoch 21/10000, Batch 110/188, Loss: 0.1959\n",
      "Epoch 21/10000, Batch 120/188, Loss: 0.2733\n",
      "Epoch 21/10000, Batch 130/188, Loss: 0.1565\n",
      "Epoch 21/10000, Batch 140/188, Loss: 0.1403\n",
      "Epoch 21/10000, Batch 150/188, Loss: 0.1589\n",
      "Epoch 21/10000, Batch 160/188, Loss: 0.1607\n",
      "Epoch 21/10000, Batch 170/188, Loss: 0.0984\n",
      "Epoch 21/10000, Batch 180/188, Loss: 0.1607\n",
      "Epoch 21 Kết thúc - Mất mát Huấn luyện: 0.2056, IoU Huấn luyện: 0.4681, F1-Score Huấn luyện: 0.6297\n",
      "Mất mát Xác thực: 0.2157, IoU Xác thực: 0.3292, F1-Score Xác thực: 0.4698\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2157. Lưu mô hình và trạng thái...\n",
      "Epoch 22/10000 Bắt đầu...\n",
      "Epoch 22/10000, Batch 10/188, Loss: 0.2182\n",
      "Epoch 22/10000, Batch 20/188, Loss: 0.1689\n",
      "Epoch 22/10000, Batch 30/188, Loss: 0.1673\n",
      "Epoch 22/10000, Batch 40/188, Loss: 0.1556\n",
      "Epoch 22/10000, Batch 50/188, Loss: 0.1310\n",
      "Epoch 22/10000, Batch 60/188, Loss: 0.2327\n",
      "Epoch 22/10000, Batch 70/188, Loss: 0.1158\n",
      "Epoch 22/10000, Batch 80/188, Loss: 0.3336\n",
      "Epoch 22/10000, Batch 90/188, Loss: 0.1633\n",
      "Epoch 22/10000, Batch 100/188, Loss: 0.2444\n",
      "Epoch 22/10000, Batch 110/188, Loss: 0.2493\n",
      "Epoch 22/10000, Batch 120/188, Loss: 0.1354\n",
      "Epoch 22/10000, Batch 130/188, Loss: 0.1549\n",
      "Epoch 22/10000, Batch 140/188, Loss: 0.1649\n",
      "Epoch 22/10000, Batch 150/188, Loss: 0.3816\n",
      "Epoch 22/10000, Batch 160/188, Loss: 0.1385\n",
      "Epoch 22/10000, Batch 170/188, Loss: 0.1937\n",
      "Epoch 22/10000, Batch 180/188, Loss: 0.1833\n",
      "Epoch 22 Kết thúc - Mất mát Huấn luyện: 0.2029, IoU Huấn luyện: 0.4725, F1-Score Huấn luyện: 0.6334\n",
      "Mất mát Xác thực: 0.2403, IoU Xác thực: 0.2922, F1-Score Xác thực: 0.4274\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 23/10000 Bắt đầu...\n",
      "Epoch 23/10000, Batch 10/188, Loss: 0.1909\n",
      "Epoch 23/10000, Batch 20/188, Loss: 0.1762\n",
      "Epoch 23/10000, Batch 30/188, Loss: 0.1704\n",
      "Epoch 23/10000, Batch 40/188, Loss: 0.2571\n",
      "Epoch 23/10000, Batch 50/188, Loss: 0.2028\n",
      "Epoch 23/10000, Batch 60/188, Loss: 0.1656\n",
      "Epoch 23/10000, Batch 70/188, Loss: 0.1122\n",
      "Epoch 23/10000, Batch 80/188, Loss: 0.2009\n",
      "Epoch 23/10000, Batch 90/188, Loss: 0.2591\n",
      "Epoch 23/10000, Batch 100/188, Loss: 0.1827\n",
      "Epoch 23/10000, Batch 110/188, Loss: 0.2578\n",
      "Epoch 23/10000, Batch 120/188, Loss: 0.2583\n",
      "Epoch 23/10000, Batch 130/188, Loss: 0.2535\n",
      "Epoch 23/10000, Batch 140/188, Loss: 0.1895\n",
      "Epoch 23/10000, Batch 150/188, Loss: 0.1643\n",
      "Epoch 23/10000, Batch 160/188, Loss: 0.1236\n",
      "Epoch 23/10000, Batch 170/188, Loss: 0.1980\n",
      "Epoch 23/10000, Batch 180/188, Loss: 0.2411\n",
      "Epoch 23 Kết thúc - Mất mát Huấn luyện: 0.1972, IoU Huấn luyện: 0.4801, F1-Score Huấn luyện: 0.6418\n",
      "Mất mát Xác thực: 0.2005, IoU Xác thực: 0.3506, F1-Score Xác thực: 0.4904\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.2005. Lưu mô hình và trạng thái...\n",
      "Epoch 24/10000 Bắt đầu...\n",
      "Epoch 24/10000, Batch 10/188, Loss: 0.2129\n",
      "Epoch 24/10000, Batch 20/188, Loss: 0.1750\n",
      "Epoch 24/10000, Batch 30/188, Loss: 0.1226\n",
      "Epoch 24/10000, Batch 40/188, Loss: 0.1357\n",
      "Epoch 24/10000, Batch 50/188, Loss: 0.1758\n",
      "Epoch 24/10000, Batch 60/188, Loss: 0.1812\n",
      "Epoch 24/10000, Batch 70/188, Loss: 0.1384\n",
      "Epoch 24/10000, Batch 80/188, Loss: 0.1977\n",
      "Epoch 24/10000, Batch 90/188, Loss: 0.1506\n",
      "Epoch 24/10000, Batch 100/188, Loss: 0.1886\n",
      "Epoch 24/10000, Batch 110/188, Loss: 0.2532\n",
      "Epoch 24/10000, Batch 120/188, Loss: 0.1443\n",
      "Epoch 24/10000, Batch 130/188, Loss: 0.1571\n",
      "Epoch 24/10000, Batch 140/188, Loss: 0.1641\n",
      "Epoch 24/10000, Batch 150/188, Loss: 0.1789\n",
      "Epoch 24/10000, Batch 160/188, Loss: 0.1881\n",
      "Epoch 24/10000, Batch 170/188, Loss: 0.2317\n",
      "Epoch 24/10000, Batch 180/188, Loss: 0.2421\n",
      "Epoch 24 Kết thúc - Mất mát Huấn luyện: 0.1978, IoU Huấn luyện: 0.4722, F1-Score Huấn luyện: 0.6322\n",
      "Mất mát Xác thực: 0.2133, IoU Xác thực: 0.3706, F1-Score Xác thực: 0.5078\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 25/10000 Bắt đầu...\n",
      "Epoch 25/10000, Batch 10/188, Loss: 0.1284\n",
      "Epoch 25/10000, Batch 20/188, Loss: 0.1951\n",
      "Epoch 25/10000, Batch 30/188, Loss: 0.1614\n",
      "Epoch 25/10000, Batch 40/188, Loss: 0.1381\n",
      "Epoch 25/10000, Batch 50/188, Loss: 0.1954\n",
      "Epoch 25/10000, Batch 60/188, Loss: 0.2105\n",
      "Epoch 25/10000, Batch 70/188, Loss: 0.1678\n",
      "Epoch 25/10000, Batch 80/188, Loss: 0.1243\n",
      "Epoch 25/10000, Batch 90/188, Loss: 0.1402\n",
      "Epoch 25/10000, Batch 100/188, Loss: 0.2486\n",
      "Epoch 25/10000, Batch 110/188, Loss: 0.2629\n",
      "Epoch 25/10000, Batch 120/188, Loss: 0.1292\n",
      "Epoch 25/10000, Batch 130/188, Loss: 0.2636\n",
      "Epoch 25/10000, Batch 140/188, Loss: 0.1705\n",
      "Epoch 25/10000, Batch 150/188, Loss: 0.2120\n",
      "Epoch 25/10000, Batch 160/188, Loss: 0.2213\n",
      "Epoch 25/10000, Batch 170/188, Loss: 0.1652\n",
      "Epoch 25/10000, Batch 180/188, Loss: 0.2073\n",
      "Epoch 25 Kết thúc - Mất mát Huấn luyện: 0.1961, IoU Huấn luyện: 0.4734, F1-Score Huấn luyện: 0.6353\n",
      "Mất mát Xác thực: 0.1980, IoU Xác thực: 0.3507, F1-Score Xác thực: 0.4925\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1980. Lưu mô hình và trạng thái...\n",
      "Epoch 26/10000 Bắt đầu...\n",
      "Epoch 26/10000, Batch 10/188, Loss: 0.2033\n",
      "Epoch 26/10000, Batch 20/188, Loss: 0.4770\n",
      "Epoch 26/10000, Batch 30/188, Loss: 0.1345\n",
      "Epoch 26/10000, Batch 40/188, Loss: 0.2025\n",
      "Epoch 26/10000, Batch 50/188, Loss: 0.1148\n",
      "Epoch 26/10000, Batch 60/188, Loss: 0.1653\n",
      "Epoch 26/10000, Batch 70/188, Loss: 0.2353\n",
      "Epoch 26/10000, Batch 80/188, Loss: 0.1560\n",
      "Epoch 26/10000, Batch 90/188, Loss: 0.1509\n",
      "Epoch 26/10000, Batch 100/188, Loss: 0.1384\n",
      "Epoch 26/10000, Batch 110/188, Loss: 0.1704\n",
      "Epoch 26/10000, Batch 120/188, Loss: 0.2062\n",
      "Epoch 26/10000, Batch 130/188, Loss: 0.1563\n",
      "Epoch 26/10000, Batch 140/188, Loss: 0.4266\n",
      "Epoch 26/10000, Batch 150/188, Loss: 0.1871\n",
      "Epoch 26/10000, Batch 160/188, Loss: 0.1551\n",
      "Epoch 26/10000, Batch 170/188, Loss: 0.1813\n",
      "Epoch 26/10000, Batch 180/188, Loss: 0.2426\n",
      "Epoch 26 Kết thúc - Mất mát Huấn luyện: 0.1899, IoU Huấn luyện: 0.4815, F1-Score Huấn luyện: 0.6436\n",
      "Mất mát Xác thực: 0.2356, IoU Xác thực: 0.3102, F1-Score Xác thực: 0.4453\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 27/10000 Bắt đầu...\n",
      "Epoch 27/10000, Batch 10/188, Loss: 0.2220\n",
      "Epoch 27/10000, Batch 20/188, Loss: 0.2266\n",
      "Epoch 27/10000, Batch 30/188, Loss: 0.1221\n",
      "Epoch 27/10000, Batch 40/188, Loss: 0.1658\n",
      "Epoch 27/10000, Batch 50/188, Loss: 0.1704\n",
      "Epoch 27/10000, Batch 60/188, Loss: 0.2677\n",
      "Epoch 27/10000, Batch 70/188, Loss: 0.1585\n",
      "Epoch 27/10000, Batch 80/188, Loss: 0.3935\n",
      "Epoch 27/10000, Batch 90/188, Loss: 0.1227\n",
      "Epoch 27/10000, Batch 100/188, Loss: 0.3172\n",
      "Epoch 27/10000, Batch 110/188, Loss: 0.1953\n",
      "Epoch 27/10000, Batch 120/188, Loss: 0.1708\n",
      "Epoch 27/10000, Batch 130/188, Loss: 0.2474\n",
      "Epoch 27/10000, Batch 140/188, Loss: 0.1746\n",
      "Epoch 27/10000, Batch 150/188, Loss: 0.2210\n",
      "Epoch 27/10000, Batch 160/188, Loss: 0.1551\n",
      "Epoch 27/10000, Batch 170/188, Loss: 0.2982\n",
      "Epoch 27/10000, Batch 180/188, Loss: 0.1592\n",
      "Epoch 27 Kết thúc - Mất mát Huấn luyện: 0.1904, IoU Huấn luyện: 0.4793, F1-Score Huấn luyện: 0.6413\n",
      "Mất mát Xác thực: 0.2058, IoU Xác thực: 0.3616, F1-Score Xác thực: 0.5038\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 2/20\n",
      "Epoch 28/10000 Bắt đầu...\n",
      "Epoch 28/10000, Batch 10/188, Loss: 0.1441\n",
      "Epoch 28/10000, Batch 20/188, Loss: 0.1591\n",
      "Epoch 28/10000, Batch 30/188, Loss: 0.2413\n",
      "Epoch 28/10000, Batch 40/188, Loss: 0.2211\n",
      "Epoch 28/10000, Batch 50/188, Loss: 0.3186\n",
      "Epoch 28/10000, Batch 60/188, Loss: 0.2948\n",
      "Epoch 28/10000, Batch 70/188, Loss: 0.1585\n",
      "Epoch 28/10000, Batch 80/188, Loss: 0.1450\n",
      "Epoch 28/10000, Batch 90/188, Loss: 0.2445\n",
      "Epoch 28/10000, Batch 100/188, Loss: 0.1547\n",
      "Epoch 28/10000, Batch 110/188, Loss: 0.2438\n",
      "Epoch 28/10000, Batch 120/188, Loss: 0.1639\n",
      "Epoch 28/10000, Batch 130/188, Loss: 0.1634\n",
      "Epoch 28/10000, Batch 140/188, Loss: 0.1479\n",
      "Epoch 28/10000, Batch 150/188, Loss: 0.1779\n",
      "Epoch 28/10000, Batch 160/188, Loss: 0.1427\n",
      "Epoch 28/10000, Batch 170/188, Loss: 0.2778\n",
      "Epoch 28/10000, Batch 180/188, Loss: 0.1242\n",
      "Epoch 28 Kết thúc - Mất mát Huấn luyện: 0.1897, IoU Huấn luyện: 0.4820, F1-Score Huấn luyện: 0.6438\n",
      "Mất mát Xác thực: 0.1986, IoU Xác thực: 0.3487, F1-Score Xác thực: 0.4926\n",
      "Learning Rate hiện tại: 0.00010000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 3/20\n",
      "Epoch 29/10000 Bắt đầu...\n",
      "Epoch 29/10000, Batch 10/188, Loss: 0.1376\n",
      "Epoch 29/10000, Batch 20/188, Loss: 0.1297\n",
      "Epoch 29/10000, Batch 30/188, Loss: 0.3360\n",
      "Epoch 29/10000, Batch 40/188, Loss: 0.1871\n",
      "Epoch 29/10000, Batch 50/188, Loss: 0.1744\n",
      "Epoch 29/10000, Batch 60/188, Loss: 0.1328\n",
      "Epoch 29/10000, Batch 70/188, Loss: 0.1813\n",
      "Epoch 29/10000, Batch 80/188, Loss: 0.2029\n",
      "Epoch 29/10000, Batch 90/188, Loss: 0.1835\n",
      "Epoch 29/10000, Batch 100/188, Loss: 0.2907\n",
      "Epoch 29/10000, Batch 110/188, Loss: 0.4326\n",
      "Epoch 29/10000, Batch 120/188, Loss: 0.1471\n",
      "Epoch 29/10000, Batch 130/188, Loss: 0.2557\n",
      "Epoch 29/10000, Batch 140/188, Loss: 0.1484\n",
      "Epoch 29/10000, Batch 150/188, Loss: 0.2340\n",
      "Epoch 29/10000, Batch 160/188, Loss: 0.1316\n",
      "Epoch 29/10000, Batch 170/188, Loss: 0.1826\n",
      "Epoch 29/10000, Batch 180/188, Loss: 0.2425\n",
      "Epoch 29 Kết thúc - Mất mát Huấn luyện: 0.1940, IoU Huấn luyện: 0.4748, F1-Score Huấn luyện: 0.6353\n",
      "Mất mát Xác thực: 0.2037, IoU Xác thực: 0.3722, F1-Score Xác thực: 0.5151\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 4/20\n",
      "Epoch 30/10000 Bắt đầu...\n",
      "Epoch 30/10000, Batch 10/188, Loss: 0.3495\n",
      "Epoch 30/10000, Batch 20/188, Loss: 0.1902\n",
      "Epoch 30/10000, Batch 30/188, Loss: 0.1453\n",
      "Epoch 30/10000, Batch 40/188, Loss: 0.1759\n",
      "Epoch 30/10000, Batch 50/188, Loss: 0.2034\n",
      "Epoch 30/10000, Batch 60/188, Loss: 0.1852\n",
      "Epoch 30/10000, Batch 70/188, Loss: 0.2351\n",
      "Epoch 30/10000, Batch 80/188, Loss: 0.1245\n",
      "Epoch 30/10000, Batch 90/188, Loss: 0.1063\n",
      "Epoch 30/10000, Batch 100/188, Loss: 0.2373\n",
      "Epoch 30/10000, Batch 110/188, Loss: 0.3538\n",
      "Epoch 30/10000, Batch 120/188, Loss: 0.2184\n",
      "Epoch 30/10000, Batch 130/188, Loss: 0.2146\n",
      "Epoch 30/10000, Batch 140/188, Loss: 0.4217\n",
      "Epoch 30/10000, Batch 150/188, Loss: 0.1798\n",
      "Epoch 30/10000, Batch 160/188, Loss: 0.1541\n",
      "Epoch 30/10000, Batch 170/188, Loss: 0.1466\n",
      "Epoch 30/10000, Batch 180/188, Loss: 0.1102\n",
      "Epoch 30 Kết thúc - Mất mát Huấn luyện: 0.1852, IoU Huấn luyện: 0.4837, F1-Score Huấn luyện: 0.6449\n",
      "Mất mát Xác thực: 0.1915, IoU Xác thực: 0.3542, F1-Score Xác thực: 0.4953\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1915. Lưu mô hình và trạng thái...\n",
      "Epoch 31/10000 Bắt đầu...\n",
      "Epoch 31/10000, Batch 10/188, Loss: 0.1278\n",
      "Epoch 31/10000, Batch 20/188, Loss: 0.1208\n",
      "Epoch 31/10000, Batch 30/188, Loss: 0.1061\n",
      "Epoch 31/10000, Batch 40/188, Loss: 0.2883\n",
      "Epoch 31/10000, Batch 50/188, Loss: 0.2571\n",
      "Epoch 31/10000, Batch 60/188, Loss: 0.1922\n",
      "Epoch 31/10000, Batch 70/188, Loss: 0.2611\n",
      "Epoch 31/10000, Batch 80/188, Loss: 0.2248\n",
      "Epoch 31/10000, Batch 90/188, Loss: 0.1531\n",
      "Epoch 31/10000, Batch 100/188, Loss: 0.3494\n",
      "Epoch 31/10000, Batch 110/188, Loss: 0.1076\n",
      "Epoch 31/10000, Batch 120/188, Loss: 0.1765\n",
      "Epoch 31/10000, Batch 130/188, Loss: 0.1927\n",
      "Epoch 31/10000, Batch 140/188, Loss: 0.1570\n",
      "Epoch 31/10000, Batch 150/188, Loss: 0.2270\n",
      "Epoch 31/10000, Batch 160/188, Loss: 0.1120\n",
      "Epoch 31/10000, Batch 170/188, Loss: 0.1679\n",
      "Epoch 31/10000, Batch 180/188, Loss: 0.4571\n",
      "Epoch 31 Kết thúc - Mất mát Huấn luyện: 0.1784, IoU Huấn luyện: 0.4886, F1-Score Huấn luyện: 0.6486\n",
      "Mất mát Xác thực: 0.1968, IoU Xác thực: 0.3713, F1-Score Xác thực: 0.5143\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 32/10000 Bắt đầu...\n",
      "Epoch 32/10000, Batch 10/188, Loss: 0.1526\n",
      "Epoch 32/10000, Batch 20/188, Loss: 0.1267\n",
      "Epoch 32/10000, Batch 30/188, Loss: 0.3317\n",
      "Epoch 32/10000, Batch 40/188, Loss: 0.1797\n",
      "Epoch 32/10000, Batch 50/188, Loss: 0.1823\n",
      "Epoch 32/10000, Batch 60/188, Loss: 0.1406\n",
      "Epoch 32/10000, Batch 70/188, Loss: 0.1631\n",
      "Epoch 32/10000, Batch 80/188, Loss: 0.1984\n",
      "Epoch 32/10000, Batch 90/188, Loss: 0.2387\n",
      "Epoch 32/10000, Batch 100/188, Loss: 0.3247\n",
      "Epoch 32/10000, Batch 110/188, Loss: 0.1874\n",
      "Epoch 32/10000, Batch 120/188, Loss: 0.1654\n",
      "Epoch 32/10000, Batch 130/188, Loss: 0.1735\n",
      "Epoch 32/10000, Batch 140/188, Loss: 0.1444\n",
      "Epoch 32/10000, Batch 150/188, Loss: 0.1434\n",
      "Epoch 32/10000, Batch 160/188, Loss: 0.1898\n",
      "Epoch 32/10000, Batch 170/188, Loss: 0.1447\n",
      "Epoch 32/10000, Batch 180/188, Loss: 0.2265\n",
      "Epoch 32 Kết thúc - Mất mát Huấn luyện: 0.1758, IoU Huấn luyện: 0.4895, F1-Score Huấn luyện: 0.6499\n",
      "Mất mát Xác thực: 0.1902, IoU Xác thực: 0.3531, F1-Score Xác thực: 0.4947\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1902. Lưu mô hình và trạng thái...\n",
      "Epoch 33/10000 Bắt đầu...\n",
      "Epoch 33/10000, Batch 10/188, Loss: 0.1374\n",
      "Epoch 33/10000, Batch 20/188, Loss: 0.2491\n",
      "Epoch 33/10000, Batch 30/188, Loss: 0.1643\n",
      "Epoch 33/10000, Batch 40/188, Loss: 0.2130\n",
      "Epoch 33/10000, Batch 50/188, Loss: 0.1634\n",
      "Epoch 33/10000, Batch 60/188, Loss: 0.2178\n",
      "Epoch 33/10000, Batch 70/188, Loss: 0.2639\n",
      "Epoch 33/10000, Batch 80/188, Loss: 0.1778\n",
      "Epoch 33/10000, Batch 90/188, Loss: 0.2709\n",
      "Epoch 33/10000, Batch 100/188, Loss: 0.1652\n",
      "Epoch 33/10000, Batch 110/188, Loss: 0.1339\n",
      "Epoch 33/10000, Batch 120/188, Loss: 0.1944\n",
      "Epoch 33/10000, Batch 130/188, Loss: 0.2024\n",
      "Epoch 33/10000, Batch 140/188, Loss: 0.1450\n",
      "Epoch 33/10000, Batch 150/188, Loss: 0.1822\n",
      "Epoch 33/10000, Batch 160/188, Loss: 0.1774\n",
      "Epoch 33/10000, Batch 170/188, Loss: 0.1844\n",
      "Epoch 33/10000, Batch 180/188, Loss: 0.1424\n",
      "Epoch 33 Kết thúc - Mất mát Huấn luyện: 0.1819, IoU Huấn luyện: 0.4874, F1-Score Huấn luyện: 0.6492\n",
      "Mất mát Xác thực: 0.1891, IoU Xác thực: 0.3789, F1-Score Xác thực: 0.5224\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1891. Lưu mô hình và trạng thái...\n",
      "Epoch 34/10000 Bắt đầu...\n",
      "Epoch 34/10000, Batch 10/188, Loss: 0.1428\n",
      "Epoch 34/10000, Batch 20/188, Loss: 0.2312\n",
      "Epoch 34/10000, Batch 30/188, Loss: 0.1816\n",
      "Epoch 34/10000, Batch 40/188, Loss: 0.1558\n",
      "Epoch 34/10000, Batch 50/188, Loss: 0.2099\n",
      "Epoch 34/10000, Batch 60/188, Loss: 0.2401\n",
      "Epoch 34/10000, Batch 70/188, Loss: 0.1533\n",
      "Epoch 34/10000, Batch 80/188, Loss: 0.1643\n",
      "Epoch 34/10000, Batch 90/188, Loss: 0.1220\n",
      "Epoch 34/10000, Batch 100/188, Loss: 0.1119\n",
      "Epoch 34/10000, Batch 110/188, Loss: 0.1379\n",
      "Epoch 34/10000, Batch 120/188, Loss: 0.1820\n",
      "Epoch 34/10000, Batch 130/188, Loss: 0.2343\n",
      "Epoch 34/10000, Batch 140/188, Loss: 0.1627\n",
      "Epoch 34/10000, Batch 150/188, Loss: 0.2226\n",
      "Epoch 34/10000, Batch 160/188, Loss: 0.1277\n",
      "Epoch 34/10000, Batch 170/188, Loss: 0.1766\n",
      "Epoch 34/10000, Batch 180/188, Loss: 0.1411\n",
      "Epoch 34 Kết thúc - Mất mát Huấn luyện: 0.1752, IoU Huấn luyện: 0.4877, F1-Score Huấn luyện: 0.6493\n",
      "Mất mát Xác thực: 0.1915, IoU Xác thực: 0.3525, F1-Score Xác thực: 0.4940\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 35/10000 Bắt đầu...\n",
      "Epoch 35/10000, Batch 10/188, Loss: 0.1657\n",
      "Epoch 35/10000, Batch 20/188, Loss: 0.1814\n",
      "Epoch 35/10000, Batch 30/188, Loss: 0.1494\n",
      "Epoch 35/10000, Batch 40/188, Loss: 0.3188\n",
      "Epoch 35/10000, Batch 50/188, Loss: 0.1761\n",
      "Epoch 35/10000, Batch 60/188, Loss: 0.1524\n",
      "Epoch 35/10000, Batch 70/188, Loss: 0.1217\n",
      "Epoch 35/10000, Batch 80/188, Loss: 0.1220\n",
      "Epoch 35/10000, Batch 90/188, Loss: 0.0935\n",
      "Epoch 35/10000, Batch 100/188, Loss: 0.1803\n",
      "Epoch 35/10000, Batch 110/188, Loss: 0.1366\n",
      "Epoch 35/10000, Batch 120/188, Loss: 0.2010\n",
      "Epoch 35/10000, Batch 130/188, Loss: 0.4402\n",
      "Epoch 35/10000, Batch 140/188, Loss: 0.1410\n",
      "Epoch 35/10000, Batch 150/188, Loss: 0.1348\n",
      "Epoch 35/10000, Batch 160/188, Loss: 0.1287\n",
      "Epoch 35/10000, Batch 170/188, Loss: 0.1435\n",
      "Epoch 35/10000, Batch 180/188, Loss: 0.1675\n",
      "Epoch 35 Kết thúc - Mất mát Huấn luyện: 0.1727, IoU Huấn luyện: 0.4930, F1-Score Huấn luyện: 0.6555\n",
      "Mất mát Xác thực: 0.1882, IoU Xác thực: 0.3631, F1-Score Xác thực: 0.5054\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1882. Lưu mô hình và trạng thái...\n",
      "Epoch 36/10000 Bắt đầu...\n",
      "Epoch 36/10000, Batch 10/188, Loss: 0.1913\n",
      "Epoch 36/10000, Batch 20/188, Loss: 0.1427\n",
      "Epoch 36/10000, Batch 30/188, Loss: 0.1217\n",
      "Epoch 36/10000, Batch 40/188, Loss: 0.4531\n",
      "Epoch 36/10000, Batch 50/188, Loss: 0.1291\n",
      "Epoch 36/10000, Batch 60/188, Loss: 0.1408\n",
      "Epoch 36/10000, Batch 70/188, Loss: 0.1425\n",
      "Epoch 36/10000, Batch 80/188, Loss: 0.1492\n",
      "Epoch 36/10000, Batch 90/188, Loss: 0.1688\n",
      "Epoch 36/10000, Batch 100/188, Loss: 0.2034\n",
      "Epoch 36/10000, Batch 110/188, Loss: 0.1802\n",
      "Epoch 36/10000, Batch 120/188, Loss: 0.1250\n",
      "Epoch 36/10000, Batch 130/188, Loss: 0.3817\n",
      "Epoch 36/10000, Batch 140/188, Loss: 0.1660\n",
      "Epoch 36/10000, Batch 150/188, Loss: 0.1830\n",
      "Epoch 36/10000, Batch 160/188, Loss: 0.1077\n",
      "Epoch 36/10000, Batch 170/188, Loss: 0.1297\n",
      "Epoch 36/10000, Batch 180/188, Loss: 0.1205\n",
      "Epoch 36 Kết thúc - Mất mát Huấn luyện: 0.1701, IoU Huấn luyện: 0.4924, F1-Score Huấn luyện: 0.6537\n",
      "Mất mát Xác thực: 0.1862, IoU Xác thực: 0.3677, F1-Score Xác thực: 0.5106\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1862. Lưu mô hình và trạng thái...\n",
      "Epoch 37/10000 Bắt đầu...\n",
      "Epoch 37/10000, Batch 10/188, Loss: 0.2329\n",
      "Epoch 37/10000, Batch 20/188, Loss: 0.3813\n",
      "Epoch 37/10000, Batch 30/188, Loss: 0.1315\n",
      "Epoch 37/10000, Batch 40/188, Loss: 0.1969\n",
      "Epoch 37/10000, Batch 50/188, Loss: 0.1356\n",
      "Epoch 37/10000, Batch 60/188, Loss: 0.1365\n",
      "Epoch 37/10000, Batch 70/188, Loss: 0.2301\n",
      "Epoch 37/10000, Batch 80/188, Loss: 0.1483\n",
      "Epoch 37/10000, Batch 90/188, Loss: 0.1294\n",
      "Epoch 37/10000, Batch 100/188, Loss: 0.1473\n",
      "Epoch 37/10000, Batch 110/188, Loss: 0.1282\n",
      "Epoch 37/10000, Batch 120/188, Loss: 0.2348\n",
      "Epoch 37/10000, Batch 130/188, Loss: 0.1007\n",
      "Epoch 37/10000, Batch 140/188, Loss: 0.1201\n",
      "Epoch 37/10000, Batch 150/188, Loss: 0.1505\n",
      "Epoch 37/10000, Batch 160/188, Loss: 0.1266\n",
      "Epoch 37/10000, Batch 170/188, Loss: 0.2709\n",
      "Epoch 37/10000, Batch 180/188, Loss: 0.2046\n",
      "Epoch 37 Kết thúc - Mất mát Huấn luyện: 0.1733, IoU Huấn luyện: 0.4949, F1-Score Huấn luyện: 0.6561\n",
      "Mất mát Xác thực: 0.1828, IoU Xác thực: 0.3743, F1-Score Xác thực: 0.5191\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1828. Lưu mô hình và trạng thái...\n",
      "Epoch 38/10000 Bắt đầu...\n",
      "Epoch 38/10000, Batch 10/188, Loss: 0.1518\n",
      "Epoch 38/10000, Batch 20/188, Loss: 0.1169\n",
      "Epoch 38/10000, Batch 30/188, Loss: 0.1837\n",
      "Epoch 38/10000, Batch 40/188, Loss: 0.2011\n",
      "Epoch 38/10000, Batch 50/188, Loss: 0.1993\n",
      "Epoch 38/10000, Batch 60/188, Loss: 0.1317\n",
      "Epoch 38/10000, Batch 70/188, Loss: 0.1063\n",
      "Epoch 38/10000, Batch 80/188, Loss: 0.2098\n",
      "Epoch 38/10000, Batch 90/188, Loss: 0.1682\n",
      "Epoch 38/10000, Batch 100/188, Loss: 0.1617\n",
      "Epoch 38/10000, Batch 110/188, Loss: 0.0714\n",
      "Epoch 38/10000, Batch 120/188, Loss: 0.1012\n",
      "Epoch 38/10000, Batch 130/188, Loss: 0.1552\n",
      "Epoch 38/10000, Batch 140/188, Loss: 0.5386\n",
      "Epoch 38/10000, Batch 150/188, Loss: 0.1866\n",
      "Epoch 38/10000, Batch 160/188, Loss: 0.1853\n",
      "Epoch 38/10000, Batch 170/188, Loss: 0.1209\n",
      "Epoch 38/10000, Batch 180/188, Loss: 0.2530\n",
      "Epoch 38 Kết thúc - Mất mát Huấn luyện: 0.1737, IoU Huấn luyện: 0.4922, F1-Score Huấn luyện: 0.6532\n",
      "Mất mát Xác thực: 0.1885, IoU Xác thực: 0.3372, F1-Score Xác thực: 0.4789\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 39/10000 Bắt đầu...\n",
      "Epoch 39/10000, Batch 10/188, Loss: 0.1607\n",
      "Epoch 39/10000, Batch 20/188, Loss: 0.1224\n",
      "Epoch 39/10000, Batch 30/188, Loss: 0.1109\n",
      "Epoch 39/10000, Batch 40/188, Loss: 0.1697\n",
      "Epoch 39/10000, Batch 50/188, Loss: 0.1987\n",
      "Epoch 39/10000, Batch 60/188, Loss: 0.1327\n",
      "Epoch 39/10000, Batch 70/188, Loss: 0.1582\n",
      "Epoch 39/10000, Batch 80/188, Loss: 0.1847\n",
      "Epoch 39/10000, Batch 90/188, Loss: 0.1059\n",
      "Epoch 39/10000, Batch 100/188, Loss: 0.1319\n",
      "Epoch 39/10000, Batch 110/188, Loss: 0.1288\n",
      "Epoch 39/10000, Batch 120/188, Loss: 0.1846\n",
      "Epoch 39/10000, Batch 130/188, Loss: 0.1248\n",
      "Epoch 39/10000, Batch 140/188, Loss: 0.1938\n",
      "Epoch 39/10000, Batch 150/188, Loss: 0.1257\n",
      "Epoch 39/10000, Batch 160/188, Loss: 0.1958\n",
      "Epoch 39/10000, Batch 170/188, Loss: 0.1772\n",
      "Epoch 39/10000, Batch 180/188, Loss: 0.1513\n",
      "Epoch 39 Kết thúc - Mất mát Huấn luyện: 0.1700, IoU Huấn luyện: 0.4909, F1-Score Huấn luyện: 0.6511\n",
      "Mất mát Xác thực: 0.1878, IoU Xác thực: 0.3674, F1-Score Xác thực: 0.5125\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 2/20\n",
      "Epoch 40/10000 Bắt đầu...\n",
      "Epoch 40/10000, Batch 10/188, Loss: 0.1217\n",
      "Epoch 40/10000, Batch 20/188, Loss: 0.2675\n",
      "Epoch 40/10000, Batch 30/188, Loss: 0.1485\n",
      "Epoch 40/10000, Batch 40/188, Loss: 0.1332\n",
      "Epoch 40/10000, Batch 50/188, Loss: 0.1297\n",
      "Epoch 40/10000, Batch 60/188, Loss: 0.1474\n",
      "Epoch 40/10000, Batch 70/188, Loss: 0.1149\n",
      "Epoch 40/10000, Batch 80/188, Loss: 0.2383\n",
      "Epoch 40/10000, Batch 90/188, Loss: 0.2004\n",
      "Epoch 40/10000, Batch 100/188, Loss: 0.1398\n",
      "Epoch 40/10000, Batch 110/188, Loss: 0.1057\n",
      "Epoch 40/10000, Batch 120/188, Loss: 0.1313\n",
      "Epoch 40/10000, Batch 130/188, Loss: 0.1438\n",
      "Epoch 40/10000, Batch 140/188, Loss: 0.1846\n",
      "Epoch 40/10000, Batch 150/188, Loss: 0.1203\n",
      "Epoch 40/10000, Batch 160/188, Loss: 0.1681\n",
      "Epoch 40/10000, Batch 170/188, Loss: 0.1373\n",
      "Epoch 40/10000, Batch 180/188, Loss: 0.1204\n",
      "Epoch 40 Kết thúc - Mất mát Huấn luyện: 0.1696, IoU Huấn luyện: 0.4931, F1-Score Huấn luyện: 0.6546\n",
      "Mất mát Xác thực: 0.1793, IoU Xác thực: 0.3624, F1-Score Xác thực: 0.5053\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1793. Lưu mô hình và trạng thái...\n",
      "Epoch 41/10000 Bắt đầu...\n",
      "Epoch 41/10000, Batch 10/188, Loss: 0.1204\n",
      "Epoch 41/10000, Batch 20/188, Loss: 0.0945\n",
      "Epoch 41/10000, Batch 30/188, Loss: 0.2072\n",
      "Epoch 41/10000, Batch 40/188, Loss: 0.1263\n",
      "Epoch 41/10000, Batch 50/188, Loss: 0.1610\n",
      "Epoch 41/10000, Batch 60/188, Loss: 0.2099\n",
      "Epoch 41/10000, Batch 70/188, Loss: 0.1371\n",
      "Epoch 41/10000, Batch 80/188, Loss: 0.1368\n",
      "Epoch 41/10000, Batch 90/188, Loss: 0.1869\n",
      "Epoch 41/10000, Batch 100/188, Loss: 0.1285\n",
      "Epoch 41/10000, Batch 110/188, Loss: 0.1251\n",
      "Epoch 41/10000, Batch 120/188, Loss: 0.1569\n",
      "Epoch 41/10000, Batch 130/188, Loss: 0.1434\n",
      "Epoch 41/10000, Batch 140/188, Loss: 0.2866\n",
      "Epoch 41/10000, Batch 150/188, Loss: 0.1378\n",
      "Epoch 41/10000, Batch 160/188, Loss: 0.1510\n",
      "Epoch 41/10000, Batch 170/188, Loss: 0.1613\n",
      "Epoch 41/10000, Batch 180/188, Loss: 0.1796\n",
      "Epoch 41 Kết thúc - Mất mát Huấn luyện: 0.1691, IoU Huấn luyện: 0.4926, F1-Score Huấn luyện: 0.6534\n",
      "Mất mát Xác thực: 0.1841, IoU Xác thực: 0.3593, F1-Score Xác thực: 0.5019\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 42/10000 Bắt đầu...\n",
      "Epoch 42/10000, Batch 10/188, Loss: 0.1688\n",
      "Epoch 42/10000, Batch 20/188, Loss: 0.1133\n",
      "Epoch 42/10000, Batch 30/188, Loss: 0.2093\n",
      "Epoch 42/10000, Batch 40/188, Loss: 0.1344\n",
      "Epoch 42/10000, Batch 50/188, Loss: 0.1757\n",
      "Epoch 42/10000, Batch 60/188, Loss: 0.1896\n",
      "Epoch 42/10000, Batch 70/188, Loss: 0.1341\n",
      "Epoch 42/10000, Batch 80/188, Loss: 0.1864\n",
      "Epoch 42/10000, Batch 90/188, Loss: 0.1133\n",
      "Epoch 42/10000, Batch 100/188, Loss: 0.0922\n",
      "Epoch 42/10000, Batch 110/188, Loss: 0.1205\n",
      "Epoch 42/10000, Batch 120/188, Loss: 0.1001\n",
      "Epoch 42/10000, Batch 130/188, Loss: 0.1650\n",
      "Epoch 42/10000, Batch 140/188, Loss: 0.2297\n",
      "Epoch 42/10000, Batch 150/188, Loss: 0.1700\n",
      "Epoch 42/10000, Batch 160/188, Loss: 0.1137\n",
      "Epoch 42/10000, Batch 170/188, Loss: 0.2141\n",
      "Epoch 42/10000, Batch 180/188, Loss: 0.3189\n",
      "Epoch 42 Kết thúc - Mất mát Huấn luyện: 0.1710, IoU Huấn luyện: 0.4917, F1-Score Huấn luyện: 0.6530\n",
      "Mất mát Xác thực: 0.1877, IoU Xác thực: 0.3764, F1-Score Xác thực: 0.5211\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 2/20\n",
      "Epoch 43/10000 Bắt đầu...\n",
      "Epoch 43/10000, Batch 10/188, Loss: 0.1944\n",
      "Epoch 43/10000, Batch 20/188, Loss: 0.2900\n",
      "Epoch 43/10000, Batch 30/188, Loss: 0.1759\n",
      "Epoch 43/10000, Batch 40/188, Loss: 0.1186\n",
      "Epoch 43/10000, Batch 50/188, Loss: 0.0983\n",
      "Epoch 43/10000, Batch 60/188, Loss: 0.2228\n",
      "Epoch 43/10000, Batch 70/188, Loss: 0.1581\n",
      "Epoch 43/10000, Batch 80/188, Loss: 0.1155\n",
      "Epoch 43/10000, Batch 90/188, Loss: 0.2153\n",
      "Epoch 43/10000, Batch 100/188, Loss: 0.1384\n",
      "Epoch 43/10000, Batch 110/188, Loss: 0.1627\n",
      "Epoch 43/10000, Batch 120/188, Loss: 0.1509\n",
      "Epoch 43/10000, Batch 130/188, Loss: 0.1960\n",
      "Epoch 43/10000, Batch 140/188, Loss: 0.1525\n",
      "Epoch 43/10000, Batch 150/188, Loss: 0.0992\n",
      "Epoch 43/10000, Batch 160/188, Loss: 0.0908\n",
      "Epoch 43/10000, Batch 170/188, Loss: 0.1218\n",
      "Epoch 43/10000, Batch 180/188, Loss: 0.1999\n",
      "Epoch 43 Kết thúc - Mất mát Huấn luyện: 0.1687, IoU Huấn luyện: 0.4990, F1-Score Huấn luyện: 0.6607\n",
      "Mất mát Xác thực: 0.1834, IoU Xác thực: 0.3669, F1-Score Xác thực: 0.5110\n",
      "Learning Rate hiện tại: 0.00005000\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 3/20\n",
      "Epoch 44/10000 Bắt đầu...\n",
      "Epoch 44/10000, Batch 10/188, Loss: 0.1718\n",
      "Epoch 44/10000, Batch 20/188, Loss: 0.1343\n",
      "Epoch 44/10000, Batch 30/188, Loss: 0.1600\n",
      "Epoch 44/10000, Batch 40/188, Loss: 0.1419\n",
      "Epoch 44/10000, Batch 50/188, Loss: 0.0978\n",
      "Epoch 44/10000, Batch 60/188, Loss: 0.3636\n",
      "Epoch 44/10000, Batch 70/188, Loss: 0.1553\n",
      "Epoch 44/10000, Batch 80/188, Loss: 0.1078\n",
      "Epoch 44/10000, Batch 90/188, Loss: 0.1254\n",
      "Epoch 44/10000, Batch 100/188, Loss: 0.1169\n",
      "Epoch 44/10000, Batch 110/188, Loss: 0.0775\n",
      "Epoch 44/10000, Batch 120/188, Loss: 0.1879\n",
      "Epoch 44/10000, Batch 130/188, Loss: 0.2408\n",
      "Epoch 44/10000, Batch 140/188, Loss: 0.1470\n",
      "Epoch 44/10000, Batch 150/188, Loss: 0.2393\n",
      "Epoch 44/10000, Batch 160/188, Loss: 0.1292\n",
      "Epoch 44/10000, Batch 170/188, Loss: 0.1803\n",
      "Epoch 44/10000, Batch 180/188, Loss: 0.1146\n",
      "Epoch 44 Kết thúc - Mất mát Huấn luyện: 0.1672, IoU Huấn luyện: 0.4998, F1-Score Huấn luyện: 0.6605\n",
      "Mất mát Xác thực: 0.1802, IoU Xác thực: 0.3716, F1-Score Xác thực: 0.5174\n",
      "Learning Rate hiện tại: 0.00002500\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 4/20\n",
      "Epoch 45/10000 Bắt đầu...\n",
      "Epoch 45/10000, Batch 10/188, Loss: 0.1383\n",
      "Epoch 45/10000, Batch 20/188, Loss: 0.1649\n",
      "Epoch 45/10000, Batch 30/188, Loss: 0.1767\n",
      "Epoch 45/10000, Batch 40/188, Loss: 0.1445\n",
      "Epoch 45/10000, Batch 50/188, Loss: 0.0966\n",
      "Epoch 45/10000, Batch 60/188, Loss: 0.1502\n",
      "Epoch 45/10000, Batch 70/188, Loss: 0.1408\n",
      "Epoch 45/10000, Batch 80/188, Loss: 0.1076\n",
      "Epoch 45/10000, Batch 90/188, Loss: 0.2946\n",
      "Epoch 45/10000, Batch 100/188, Loss: 0.2163\n",
      "Epoch 45/10000, Batch 110/188, Loss: 0.0938\n",
      "Epoch 45/10000, Batch 120/188, Loss: 0.1141\n",
      "Epoch 45/10000, Batch 130/188, Loss: 0.1692\n",
      "Epoch 45/10000, Batch 140/188, Loss: 0.1905\n",
      "Epoch 45/10000, Batch 150/188, Loss: 0.1228\n",
      "Epoch 45/10000, Batch 160/188, Loss: 0.1062\n",
      "Epoch 45/10000, Batch 170/188, Loss: 0.1345\n",
      "Epoch 45/10000, Batch 180/188, Loss: 0.1362\n",
      "Epoch 45 Kết thúc - Mất mát Huấn luyện: 0.1631, IoU Huấn luyện: 0.5070, F1-Score Huấn luyện: 0.6672\n",
      "Mất mát Xác thực: 0.1775, IoU Xác thực: 0.3685, F1-Score Xác thực: 0.5124\n",
      "Learning Rate hiện tại: 0.00002500\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1775. Lưu mô hình và trạng thái...\n",
      "Epoch 46/10000 Bắt đầu...\n",
      "Epoch 46/10000, Batch 10/188, Loss: 0.1239\n",
      "Epoch 46/10000, Batch 20/188, Loss: 0.1248\n",
      "Epoch 46/10000, Batch 30/188, Loss: 0.1760\n",
      "Epoch 46/10000, Batch 40/188, Loss: 0.1017\n",
      "Epoch 46/10000, Batch 50/188, Loss: 0.1250\n",
      "Epoch 46/10000, Batch 60/188, Loss: 0.1482\n",
      "Epoch 46/10000, Batch 70/188, Loss: 0.1468\n",
      "Epoch 46/10000, Batch 80/188, Loss: 0.1439\n",
      "Epoch 46/10000, Batch 90/188, Loss: 0.1556\n",
      "Epoch 46/10000, Batch 100/188, Loss: 0.1747\n",
      "Epoch 46/10000, Batch 110/188, Loss: 0.1269\n",
      "Epoch 46/10000, Batch 120/188, Loss: 0.1522\n",
      "Epoch 46/10000, Batch 130/188, Loss: 0.0996\n",
      "Epoch 46/10000, Batch 140/188, Loss: 0.2457\n",
      "Epoch 46/10000, Batch 150/188, Loss: 0.1598\n",
      "Epoch 46/10000, Batch 160/188, Loss: 0.2965\n",
      "Epoch 46/10000, Batch 170/188, Loss: 0.1117\n",
      "Epoch 46/10000, Batch 180/188, Loss: 0.1012\n",
      "Epoch 46 Kết thúc - Mất mát Huấn luyện: 0.1609, IoU Huấn luyện: 0.5077, F1-Score Huấn luyện: 0.6690\n",
      "Mất mát Xác thực: 0.1769, IoU Xác thực: 0.3685, F1-Score Xác thực: 0.5123\n",
      "Learning Rate hiện tại: 0.00002500\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1769. Lưu mô hình và trạng thái...\n",
      "Epoch 47/10000 Bắt đầu...\n",
      "Epoch 47/10000, Batch 10/188, Loss: 0.1353\n",
      "Epoch 47/10000, Batch 20/188, Loss: 0.1309\n",
      "Epoch 47/10000, Batch 30/188, Loss: 0.4101\n",
      "Epoch 47/10000, Batch 40/188, Loss: 0.2238\n",
      "Epoch 47/10000, Batch 50/188, Loss: 0.1110\n",
      "Epoch 47/10000, Batch 60/188, Loss: 0.1055\n",
      "Epoch 47/10000, Batch 70/188, Loss: 0.1346\n",
      "Epoch 47/10000, Batch 80/188, Loss: 0.1705\n",
      "Epoch 47/10000, Batch 90/188, Loss: 0.1321\n",
      "Epoch 47/10000, Batch 100/188, Loss: 0.1187\n",
      "Epoch 47/10000, Batch 110/188, Loss: 0.1570\n",
      "Epoch 47/10000, Batch 120/188, Loss: 0.1063\n",
      "Epoch 47/10000, Batch 130/188, Loss: 0.2859\n",
      "Epoch 47/10000, Batch 140/188, Loss: 0.1599\n",
      "Epoch 47/10000, Batch 150/188, Loss: 0.1686\n",
      "Epoch 47/10000, Batch 160/188, Loss: 0.1435\n",
      "Epoch 47/10000, Batch 170/188, Loss: 0.1718\n",
      "Epoch 47/10000, Batch 180/188, Loss: 0.2023\n",
      "Epoch 47 Kết thúc - Mất mát Huấn luyện: 0.1623, IoU Huấn luyện: 0.5035, F1-Score Huấn luyện: 0.6639\n",
      "Mất mát Xác thực: 0.1808, IoU Xác thực: 0.3596, F1-Score Xác thực: 0.5028\n",
      "Learning Rate hiện tại: 0.00002500\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 48/10000 Bắt đầu...\n",
      "Epoch 48/10000, Batch 10/188, Loss: 0.1596\n",
      "Epoch 48/10000, Batch 20/188, Loss: 0.1051\n",
      "Epoch 48/10000, Batch 30/188, Loss: 0.1340\n",
      "Epoch 48/10000, Batch 40/188, Loss: 0.1123\n",
      "Epoch 48/10000, Batch 50/188, Loss: 0.1873\n",
      "Epoch 48/10000, Batch 60/188, Loss: 0.1659\n",
      "Epoch 48/10000, Batch 70/188, Loss: 0.3231\n",
      "Epoch 48/10000, Batch 80/188, Loss: 0.0786\n",
      "Epoch 48/10000, Batch 90/188, Loss: 0.1225\n",
      "Epoch 48/10000, Batch 100/188, Loss: 0.1649\n",
      "Epoch 48/10000, Batch 110/188, Loss: 0.3058\n",
      "Epoch 48/10000, Batch 120/188, Loss: 0.2459\n",
      "Epoch 48/10000, Batch 130/188, Loss: 0.1186\n",
      "Epoch 48/10000, Batch 140/188, Loss: 0.2019\n",
      "Epoch 48/10000, Batch 150/188, Loss: 0.1672\n",
      "Epoch 48/10000, Batch 160/188, Loss: 0.1064\n",
      "Epoch 48/10000, Batch 170/188, Loss: 0.1280\n",
      "Epoch 48/10000, Batch 180/188, Loss: 0.2950\n",
      "Epoch 48 Kết thúc - Mất mát Huấn luyện: 0.1608, IoU Huấn luyện: 0.5041, F1-Score Huấn luyện: 0.6646\n",
      "Mất mát Xác thực: 0.1773, IoU Xác thực: 0.3590, F1-Score Xác thực: 0.5019\n",
      "Learning Rate hiện tại: 0.00002500\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 2/20\n",
      "Epoch 49/10000 Bắt đầu...\n",
      "Epoch 49/10000, Batch 10/188, Loss: 0.1647\n",
      "Epoch 49/10000, Batch 20/188, Loss: 0.2342\n",
      "Epoch 49/10000, Batch 30/188, Loss: 0.1290\n",
      "Epoch 49/10000, Batch 40/188, Loss: 0.1425\n",
      "Epoch 49/10000, Batch 50/188, Loss: 0.1237\n",
      "Epoch 49/10000, Batch 60/188, Loss: 0.1452\n",
      "Epoch 49/10000, Batch 70/188, Loss: 0.1925\n",
      "Epoch 49/10000, Batch 80/188, Loss: 0.0896\n",
      "Epoch 49/10000, Batch 90/188, Loss: 0.2325\n",
      "Epoch 49/10000, Batch 100/188, Loss: 0.1403\n",
      "Epoch 49/10000, Batch 110/188, Loss: 0.1268\n",
      "Epoch 49/10000, Batch 120/188, Loss: 0.1405\n",
      "Epoch 49/10000, Batch 130/188, Loss: 0.1338\n",
      "Epoch 49/10000, Batch 140/188, Loss: 0.1307\n",
      "Epoch 49/10000, Batch 150/188, Loss: 0.0885\n",
      "Epoch 49/10000, Batch 160/188, Loss: 0.1653\n",
      "Epoch 49/10000, Batch 170/188, Loss: 0.1472\n",
      "Epoch 49/10000, Batch 180/188, Loss: 0.1849\n",
      "Epoch 49 Kết thúc - Mất mát Huấn luyện: 0.1599, IoU Huấn luyện: 0.5023, F1-Score Huấn luyện: 0.6621\n",
      "Mất mát Xác thực: 0.1800, IoU Xác thực: 0.3614, F1-Score Xác thực: 0.5052\n",
      "Learning Rate hiện tại: 0.00002500\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 3/20\n",
      "Epoch 50/10000 Bắt đầu...\n",
      "Epoch 50/10000, Batch 10/188, Loss: 0.1281\n",
      "Epoch 50/10000, Batch 20/188, Loss: 0.3945\n",
      "Epoch 50/10000, Batch 30/188, Loss: 0.1122\n",
      "Epoch 50/10000, Batch 40/188, Loss: 0.2237\n",
      "Epoch 50/10000, Batch 50/188, Loss: 0.2083\n",
      "Epoch 50/10000, Batch 60/188, Loss: 0.1612\n",
      "Epoch 50/10000, Batch 70/188, Loss: 0.1496\n",
      "Epoch 50/10000, Batch 80/188, Loss: 0.1271\n",
      "Epoch 50/10000, Batch 90/188, Loss: 0.1929\n",
      "Epoch 50/10000, Batch 100/188, Loss: 0.1490\n",
      "Epoch 50/10000, Batch 110/188, Loss: 0.1837\n",
      "Epoch 50/10000, Batch 120/188, Loss: 0.1307\n",
      "Epoch 50/10000, Batch 130/188, Loss: 0.1699\n",
      "Epoch 50/10000, Batch 140/188, Loss: 0.1360\n",
      "Epoch 50/10000, Batch 150/188, Loss: 0.2174\n",
      "Epoch 50/10000, Batch 160/188, Loss: 0.1388\n",
      "Epoch 50/10000, Batch 170/188, Loss: 0.1574\n",
      "Epoch 50/10000, Batch 180/188, Loss: 0.1377\n",
      "Epoch 50 Kết thúc - Mất mát Huấn luyện: 0.1616, IoU Huấn luyện: 0.4981, F1-Score Huấn luyện: 0.6579\n",
      "Mất mát Xác thực: 0.1807, IoU Xác thực: 0.3609, F1-Score Xác thực: 0.5053\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 4/20\n",
      "Epoch 51/10000 Bắt đầu...\n",
      "Epoch 51/10000, Batch 10/188, Loss: 0.1453\n",
      "Epoch 51/10000, Batch 20/188, Loss: 0.1424\n",
      "Epoch 51/10000, Batch 30/188, Loss: 0.1529\n",
      "Epoch 51/10000, Batch 40/188, Loss: 0.3156\n",
      "Epoch 51/10000, Batch 50/188, Loss: 0.2274\n",
      "Epoch 51/10000, Batch 60/188, Loss: 0.1751\n",
      "Epoch 51/10000, Batch 70/188, Loss: 0.1435\n",
      "Epoch 51/10000, Batch 80/188, Loss: 0.1487\n",
      "Epoch 51/10000, Batch 90/188, Loss: 0.1434\n",
      "Epoch 51/10000, Batch 100/188, Loss: 0.1894\n",
      "Epoch 51/10000, Batch 110/188, Loss: 0.1231\n",
      "Epoch 51/10000, Batch 120/188, Loss: 0.1199\n",
      "Epoch 51/10000, Batch 130/188, Loss: 0.1873\n",
      "Epoch 51/10000, Batch 140/188, Loss: 0.0998\n",
      "Epoch 51/10000, Batch 150/188, Loss: 0.1672\n",
      "Epoch 51/10000, Batch 160/188, Loss: 0.1305\n",
      "Epoch 51/10000, Batch 170/188, Loss: 0.1248\n",
      "Epoch 51/10000, Batch 180/188, Loss: 0.1568\n",
      "Epoch 51 Kết thúc - Mất mát Huấn luyện: 0.1600, IoU Huấn luyện: 0.5039, F1-Score Huấn luyện: 0.6644\n",
      "Mất mát Xác thực: 0.1777, IoU Xác thực: 0.3757, F1-Score Xác thực: 0.5208\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 5/20\n",
      "Epoch 52/10000 Bắt đầu...\n",
      "Epoch 52/10000, Batch 10/188, Loss: 0.1267\n",
      "Epoch 52/10000, Batch 20/188, Loss: 0.5356\n",
      "Epoch 52/10000, Batch 30/188, Loss: 0.2130\n",
      "Epoch 52/10000, Batch 40/188, Loss: 0.1411\n",
      "Epoch 52/10000, Batch 50/188, Loss: 0.1303\n",
      "Epoch 52/10000, Batch 60/188, Loss: 0.1558\n",
      "Epoch 52/10000, Batch 70/188, Loss: 0.1473\n",
      "Epoch 52/10000, Batch 80/188, Loss: 0.2037\n",
      "Epoch 52/10000, Batch 90/188, Loss: 0.1242\n",
      "Epoch 52/10000, Batch 100/188, Loss: 0.1063\n",
      "Epoch 52/10000, Batch 110/188, Loss: 0.1558\n",
      "Epoch 52/10000, Batch 120/188, Loss: 0.1361\n",
      "Epoch 52/10000, Batch 130/188, Loss: 0.1211\n",
      "Epoch 52/10000, Batch 140/188, Loss: 0.1642\n",
      "Epoch 52/10000, Batch 150/188, Loss: 0.1335\n",
      "Epoch 52/10000, Batch 160/188, Loss: 0.0979\n",
      "Epoch 52/10000, Batch 170/188, Loss: 0.1059\n",
      "Epoch 52/10000, Batch 180/188, Loss: 0.1080\n",
      "Epoch 52 Kết thúc - Mất mát Huấn luyện: 0.1574, IoU Huấn luyện: 0.5089, F1-Score Huấn luyện: 0.6690\n",
      "Mất mát Xác thực: 0.1774, IoU Xác thực: 0.3739, F1-Score Xác thực: 0.5189\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 6/20\n",
      "Epoch 53/10000 Bắt đầu...\n",
      "Epoch 53/10000, Batch 10/188, Loss: 0.1248\n",
      "Epoch 53/10000, Batch 20/188, Loss: 0.1309\n",
      "Epoch 53/10000, Batch 30/188, Loss: 0.0954\n",
      "Epoch 53/10000, Batch 40/188, Loss: 0.1546\n",
      "Epoch 53/10000, Batch 50/188, Loss: 0.2447\n",
      "Epoch 53/10000, Batch 60/188, Loss: 0.1377\n",
      "Epoch 53/10000, Batch 70/188, Loss: 0.1309\n",
      "Epoch 53/10000, Batch 80/188, Loss: 0.1343\n",
      "Epoch 53/10000, Batch 90/188, Loss: 0.1523\n",
      "Epoch 53/10000, Batch 100/188, Loss: 0.1163\n",
      "Epoch 53/10000, Batch 110/188, Loss: 0.1108\n",
      "Epoch 53/10000, Batch 120/188, Loss: 0.1074\n",
      "Epoch 53/10000, Batch 130/188, Loss: 0.1304\n",
      "Epoch 53/10000, Batch 140/188, Loss: 0.1285\n",
      "Epoch 53/10000, Batch 150/188, Loss: 0.1447\n",
      "Epoch 53/10000, Batch 160/188, Loss: 0.1303\n",
      "Epoch 53/10000, Batch 170/188, Loss: 0.1692\n",
      "Epoch 53/10000, Batch 180/188, Loss: 0.1456\n",
      "Epoch 53 Kết thúc - Mất mát Huấn luyện: 0.1548, IoU Huấn luyện: 0.5060, F1-Score Huấn luyện: 0.6662\n",
      "Mất mát Xác thực: 0.1802, IoU Xác thực: 0.3701, F1-Score Xác thực: 0.5143\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 7/20\n",
      "Epoch 54/10000 Bắt đầu...\n",
      "Epoch 54/10000, Batch 10/188, Loss: 0.1823\n",
      "Epoch 54/10000, Batch 20/188, Loss: 0.1302\n",
      "Epoch 54/10000, Batch 30/188, Loss: 0.3709\n",
      "Epoch 54/10000, Batch 40/188, Loss: 0.1018\n",
      "Epoch 54/10000, Batch 50/188, Loss: 0.1933\n",
      "Epoch 54/10000, Batch 60/188, Loss: 0.1438\n",
      "Epoch 54/10000, Batch 70/188, Loss: 0.1740\n",
      "Epoch 54/10000, Batch 80/188, Loss: 0.1374\n",
      "Epoch 54/10000, Batch 90/188, Loss: 0.1812\n",
      "Epoch 54/10000, Batch 100/188, Loss: 0.1319\n",
      "Epoch 54/10000, Batch 110/188, Loss: 0.4620\n",
      "Epoch 54/10000, Batch 120/188, Loss: 0.1880\n",
      "Epoch 54/10000, Batch 130/188, Loss: 0.1351\n",
      "Epoch 54/10000, Batch 140/188, Loss: 0.1296\n",
      "Epoch 54/10000, Batch 150/188, Loss: 0.3582\n",
      "Epoch 54/10000, Batch 160/188, Loss: 0.1418\n",
      "Epoch 54/10000, Batch 170/188, Loss: 0.2222\n",
      "Epoch 54/10000, Batch 180/188, Loss: 0.2380\n",
      "Epoch 54 Kết thúc - Mất mát Huấn luyện: 0.1608, IoU Huấn luyện: 0.5069, F1-Score Huấn luyện: 0.6667\n",
      "Mất mát Xác thực: 0.1754, IoU Xác thực: 0.3740, F1-Score Xác thực: 0.5185\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1754. Lưu mô hình và trạng thái...\n",
      "Epoch 55/10000 Bắt đầu...\n",
      "Epoch 55/10000, Batch 10/188, Loss: 0.2211\n",
      "Epoch 55/10000, Batch 20/188, Loss: 0.1415\n",
      "Epoch 55/10000, Batch 30/188, Loss: 0.1223\n",
      "Epoch 55/10000, Batch 40/188, Loss: 0.1148\n",
      "Epoch 55/10000, Batch 50/188, Loss: 0.1385\n",
      "Epoch 55/10000, Batch 60/188, Loss: 0.1694\n",
      "Epoch 55/10000, Batch 70/188, Loss: 0.1900\n",
      "Epoch 55/10000, Batch 80/188, Loss: 0.1721\n",
      "Epoch 55/10000, Batch 90/188, Loss: 0.1193\n",
      "Epoch 55/10000, Batch 100/188, Loss: 0.1587\n",
      "Epoch 55/10000, Batch 110/188, Loss: 0.2014\n",
      "Epoch 55/10000, Batch 120/188, Loss: 0.1137\n",
      "Epoch 55/10000, Batch 130/188, Loss: 0.1063\n",
      "Epoch 55/10000, Batch 140/188, Loss: 0.1197\n",
      "Epoch 55/10000, Batch 150/188, Loss: 0.1544\n",
      "Epoch 55/10000, Batch 160/188, Loss: 0.1688\n",
      "Epoch 55/10000, Batch 170/188, Loss: 0.1669\n",
      "Epoch 55/10000, Batch 180/188, Loss: 0.1497\n",
      "Epoch 55 Kết thúc - Mất mát Huấn luyện: 0.1574, IoU Huấn luyện: 0.5100, F1-Score Huấn luyện: 0.6700\n",
      "Mất mát Xác thực: 0.1775, IoU Xác thực: 0.3615, F1-Score Xác thực: 0.5063\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 56/10000 Bắt đầu...\n",
      "Epoch 56/10000, Batch 10/188, Loss: 0.1377\n",
      "Epoch 56/10000, Batch 20/188, Loss: 0.2642\n",
      "Epoch 56/10000, Batch 30/188, Loss: 0.3826\n",
      "Epoch 56/10000, Batch 40/188, Loss: 0.2170\n",
      "Epoch 56/10000, Batch 50/188, Loss: 0.1468\n",
      "Epoch 56/10000, Batch 60/188, Loss: 0.2060\n",
      "Epoch 56/10000, Batch 70/188, Loss: 0.2522\n",
      "Epoch 56/10000, Batch 80/188, Loss: 0.1108\n",
      "Epoch 56/10000, Batch 90/188, Loss: 0.1580\n",
      "Epoch 56/10000, Batch 100/188, Loss: 0.1418\n",
      "Epoch 56/10000, Batch 110/188, Loss: 0.1636\n",
      "Epoch 56/10000, Batch 120/188, Loss: 0.1727\n",
      "Epoch 56/10000, Batch 130/188, Loss: 0.1728\n",
      "Epoch 56/10000, Batch 140/188, Loss: 0.1143\n",
      "Epoch 56/10000, Batch 150/188, Loss: 0.1213\n",
      "Epoch 56/10000, Batch 160/188, Loss: 0.1383\n",
      "Epoch 56/10000, Batch 170/188, Loss: 0.1034\n",
      "Epoch 56/10000, Batch 180/188, Loss: 0.2295\n",
      "Epoch 56 Kết thúc - Mất mát Huấn luyện: 0.1566, IoU Huấn luyện: 0.5074, F1-Score Huấn luyện: 0.6668\n",
      "Mất mát Xác thực: 0.1774, IoU Xác thực: 0.3721, F1-Score Xác thực: 0.5172\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 2/20\n",
      "Epoch 57/10000 Bắt đầu...\n",
      "Epoch 57/10000, Batch 10/188, Loss: 0.0992\n",
      "Epoch 57/10000, Batch 20/188, Loss: 0.2015\n",
      "Epoch 57/10000, Batch 30/188, Loss: 0.0826\n",
      "Epoch 57/10000, Batch 40/188, Loss: 0.1830\n",
      "Epoch 57/10000, Batch 50/188, Loss: 0.2289\n",
      "Epoch 57/10000, Batch 60/188, Loss: 0.1465\n",
      "Epoch 57/10000, Batch 70/188, Loss: 0.0971\n",
      "Epoch 57/10000, Batch 80/188, Loss: 0.1221\n",
      "Epoch 57/10000, Batch 90/188, Loss: 0.1284\n",
      "Epoch 57/10000, Batch 100/188, Loss: 0.1554\n",
      "Epoch 57/10000, Batch 110/188, Loss: 0.1807\n",
      "Epoch 57/10000, Batch 120/188, Loss: 0.1201\n",
      "Epoch 57/10000, Batch 130/188, Loss: 0.1336\n",
      "Epoch 57/10000, Batch 140/188, Loss: 0.1344\n",
      "Epoch 57/10000, Batch 150/188, Loss: 0.1079\n",
      "Epoch 57/10000, Batch 160/188, Loss: 0.1323\n",
      "Epoch 57/10000, Batch 170/188, Loss: 0.1309\n",
      "Epoch 57/10000, Batch 180/188, Loss: 0.2061\n",
      "Epoch 57 Kết thúc - Mất mát Huấn luyện: 0.1543, IoU Huấn luyện: 0.5089, F1-Score Huấn luyện: 0.6690\n",
      "Mất mát Xác thực: 0.1737, IoU Xác thực: 0.3750, F1-Score Xác thực: 0.5199\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực tốt nhất được cập nhật: 0.1737. Lưu mô hình và trạng thái...\n",
      "Epoch 58/10000 Bắt đầu...\n",
      "Epoch 58/10000, Batch 10/188, Loss: 0.1432\n",
      "Epoch 58/10000, Batch 20/188, Loss: 0.2186\n",
      "Epoch 58/10000, Batch 30/188, Loss: 0.1242\n",
      "Epoch 58/10000, Batch 40/188, Loss: 0.1913\n",
      "Epoch 58/10000, Batch 50/188, Loss: 0.1430\n",
      "Epoch 58/10000, Batch 60/188, Loss: 0.1580\n",
      "Epoch 58/10000, Batch 70/188, Loss: 0.0655\n",
      "Epoch 58/10000, Batch 80/188, Loss: 0.1740\n",
      "Epoch 58/10000, Batch 90/188, Loss: 0.0958\n",
      "Epoch 58/10000, Batch 100/188, Loss: 0.1497\n",
      "Epoch 58/10000, Batch 110/188, Loss: 0.1328\n",
      "Epoch 58/10000, Batch 120/188, Loss: 0.1852\n",
      "Epoch 58/10000, Batch 130/188, Loss: 0.1656\n",
      "Epoch 58/10000, Batch 140/188, Loss: 0.1918\n",
      "Epoch 58/10000, Batch 150/188, Loss: 0.1845\n",
      "Epoch 58/10000, Batch 160/188, Loss: 0.1083\n",
      "Epoch 58/10000, Batch 170/188, Loss: 0.1723\n",
      "Epoch 58/10000, Batch 180/188, Loss: 0.1407\n",
      "Epoch 58 Kết thúc - Mất mát Huấn luyện: 0.1574, IoU Huấn luyện: 0.5085, F1-Score Huấn luyện: 0.6691\n",
      "Mất mát Xác thực: 0.1738, IoU Xác thực: 0.3770, F1-Score Xác thực: 0.5222\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 1/20\n",
      "Epoch 59/10000 Bắt đầu...\n",
      "Epoch 59/10000, Batch 10/188, Loss: 0.1971\n",
      "Epoch 59/10000, Batch 20/188, Loss: 0.1220\n",
      "Epoch 59/10000, Batch 30/188, Loss: 0.1567\n",
      "Epoch 59/10000, Batch 40/188, Loss: 0.1073\n",
      "Epoch 59/10000, Batch 50/188, Loss: 0.1572\n",
      "Epoch 59/10000, Batch 60/188, Loss: 0.1905\n",
      "Epoch 59/10000, Batch 70/188, Loss: 0.0993\n",
      "Epoch 59/10000, Batch 80/188, Loss: 0.1421\n",
      "Epoch 59/10000, Batch 90/188, Loss: 0.1979\n",
      "Epoch 59/10000, Batch 100/188, Loss: 0.1364\n",
      "Epoch 59/10000, Batch 110/188, Loss: 0.1399\n",
      "Epoch 59/10000, Batch 120/188, Loss: 0.0968\n",
      "Epoch 59/10000, Batch 130/188, Loss: 0.1455\n",
      "Epoch 59/10000, Batch 140/188, Loss: 0.1572\n",
      "Epoch 59/10000, Batch 150/188, Loss: 0.2565\n",
      "Epoch 59/10000, Batch 160/188, Loss: 0.1431\n",
      "Epoch 59/10000, Batch 170/188, Loss: 0.2143\n",
      "Epoch 59/10000, Batch 180/188, Loss: 0.1732\n",
      "Epoch 59 Kết thúc - Mất mát Huấn luyện: 0.1556, IoU Huấn luyện: 0.5073, F1-Score Huấn luyện: 0.6676\n",
      "Mất mát Xác thực: 0.1762, IoU Xác thực: 0.3797, F1-Score Xác thực: 0.5251\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 2/20\n",
      "Epoch 60/10000 Bắt đầu...\n",
      "Epoch 60/10000, Batch 10/188, Loss: 0.1495\n",
      "Epoch 60/10000, Batch 20/188, Loss: 0.1148\n",
      "Epoch 60/10000, Batch 30/188, Loss: 0.1489\n",
      "Epoch 60/10000, Batch 40/188, Loss: 0.1159\n",
      "Epoch 60/10000, Batch 50/188, Loss: 0.1269\n",
      "Epoch 60/10000, Batch 60/188, Loss: 0.2627\n",
      "Epoch 60/10000, Batch 70/188, Loss: 0.1312\n",
      "Epoch 60/10000, Batch 80/188, Loss: 0.0936\n",
      "Epoch 60/10000, Batch 90/188, Loss: 0.1370\n",
      "Epoch 60/10000, Batch 100/188, Loss: 0.1549\n",
      "Epoch 60/10000, Batch 110/188, Loss: 0.1574\n",
      "Epoch 60/10000, Batch 120/188, Loss: 0.1946\n",
      "Epoch 60/10000, Batch 130/188, Loss: 0.1798\n",
      "Epoch 60/10000, Batch 140/188, Loss: 0.1391\n",
      "Epoch 60/10000, Batch 150/188, Loss: 0.2719\n",
      "Epoch 60/10000, Batch 160/188, Loss: 0.1512\n",
      "Epoch 60/10000, Batch 170/188, Loss: 0.1602\n",
      "Epoch 60/10000, Batch 180/188, Loss: 0.0788\n",
      "Epoch 60 Kết thúc - Mất mát Huấn luyện: 0.1579, IoU Huấn luyện: 0.5093, F1-Score Huấn luyện: 0.6684\n",
      "Mất mát Xác thực: 0.1741, IoU Xác thực: 0.3818, F1-Score Xác thực: 0.5273\n",
      "Learning Rate hiện tại: 0.00001250\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 3/20\n",
      "Epoch 61/10000 Bắt đầu...\n",
      "Epoch 61/10000, Batch 10/188, Loss: 0.1240\n",
      "Epoch 61/10000, Batch 20/188, Loss: 0.1630\n",
      "Epoch 61/10000, Batch 30/188, Loss: 0.1009\n",
      "Epoch 61/10000, Batch 40/188, Loss: 0.1791\n",
      "Epoch 61/10000, Batch 50/188, Loss: 0.2009\n",
      "Epoch 61/10000, Batch 60/188, Loss: 0.1521\n",
      "Epoch 61/10000, Batch 70/188, Loss: 0.1271\n",
      "Epoch 61/10000, Batch 80/188, Loss: 0.1970\n",
      "Epoch 61/10000, Batch 90/188, Loss: 0.1928\n",
      "Epoch 61/10000, Batch 100/188, Loss: 0.1219\n",
      "Epoch 61/10000, Batch 110/188, Loss: 0.1353\n",
      "Epoch 61/10000, Batch 120/188, Loss: 0.1212\n",
      "Epoch 61/10000, Batch 130/188, Loss: 0.1387\n",
      "Epoch 61/10000, Batch 140/188, Loss: 0.1379\n",
      "Epoch 61/10000, Batch 150/188, Loss: 0.4122\n",
      "Epoch 61/10000, Batch 160/188, Loss: 0.1166\n",
      "Epoch 61/10000, Batch 170/188, Loss: 0.1725\n",
      "Epoch 61/10000, Batch 180/188, Loss: 0.1471\n",
      "Epoch 61 Kết thúc - Mất mát Huấn luyện: 0.1586, IoU Huấn luyện: 0.5032, F1-Score Huấn luyện: 0.6629\n",
      "Mất mát Xác thực: 0.1744, IoU Xác thực: 0.3814, F1-Score Xác thực: 0.5271\n",
      "Learning Rate hiện tại: 0.00000625\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 4/20\n",
      "Epoch 62/10000 Bắt đầu...\n",
      "Epoch 62/10000, Batch 10/188, Loss: 0.1201\n",
      "Epoch 62/10000, Batch 20/188, Loss: 0.1181\n",
      "Epoch 62/10000, Batch 30/188, Loss: 0.1720\n",
      "Epoch 62/10000, Batch 40/188, Loss: 0.1928\n",
      "Epoch 62/10000, Batch 50/188, Loss: 0.1088\n",
      "Epoch 62/10000, Batch 60/188, Loss: 0.1098\n",
      "Epoch 62/10000, Batch 70/188, Loss: 0.1334\n",
      "Epoch 62/10000, Batch 80/188, Loss: 0.1399\n",
      "Epoch 62/10000, Batch 90/188, Loss: 0.2023\n",
      "Epoch 62/10000, Batch 100/188, Loss: 0.2193\n",
      "Epoch 62/10000, Batch 110/188, Loss: 0.1894\n",
      "Epoch 62/10000, Batch 120/188, Loss: 0.1844\n",
      "Epoch 62/10000, Batch 130/188, Loss: 0.1291\n",
      "Epoch 62/10000, Batch 140/188, Loss: 0.2010\n",
      "Epoch 62/10000, Batch 150/188, Loss: 0.1302\n",
      "Epoch 62/10000, Batch 160/188, Loss: 0.0892\n",
      "Epoch 62/10000, Batch 170/188, Loss: 0.1297\n",
      "Epoch 62/10000, Batch 180/188, Loss: 0.1410\n",
      "Epoch 62 Kết thúc - Mất mát Huấn luyện: 0.1536, IoU Huấn luyện: 0.5132, F1-Score Huấn luyện: 0.6736\n",
      "Mất mát Xác thực: 0.1761, IoU Xác thực: 0.3648, F1-Score Xác thực: 0.5090\n",
      "Learning Rate hiện tại: 0.00000625\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 5/20\n",
      "Epoch 63/10000 Bắt đầu...\n",
      "Epoch 63/10000, Batch 10/188, Loss: 0.1037\n",
      "Epoch 63/10000, Batch 20/188, Loss: 0.1080\n",
      "Epoch 63/10000, Batch 30/188, Loss: 0.1552\n",
      "Epoch 63/10000, Batch 40/188, Loss: 0.0925\n",
      "Epoch 63/10000, Batch 50/188, Loss: 0.2279\n",
      "Epoch 63/10000, Batch 60/188, Loss: 0.1770\n",
      "Epoch 63/10000, Batch 70/188, Loss: 0.2031\n",
      "Epoch 63/10000, Batch 80/188, Loss: 0.1203\n",
      "Epoch 63/10000, Batch 90/188, Loss: 0.1572\n",
      "Epoch 63/10000, Batch 100/188, Loss: 0.2522\n",
      "Epoch 63/10000, Batch 110/188, Loss: 0.1065\n",
      "Epoch 63/10000, Batch 120/188, Loss: 0.2934\n",
      "Epoch 63/10000, Batch 130/188, Loss: 0.1540\n",
      "Epoch 63/10000, Batch 140/188, Loss: 0.1568\n",
      "Epoch 63/10000, Batch 150/188, Loss: 0.2211\n",
      "Epoch 63/10000, Batch 160/188, Loss: 0.1647\n",
      "Epoch 63/10000, Batch 170/188, Loss: 0.2184\n",
      "Epoch 63/10000, Batch 180/188, Loss: 0.1877\n",
      "Epoch 63 Kết thúc - Mất mát Huấn luyện: 0.1562, IoU Huấn luyện: 0.5084, F1-Score Huấn luyện: 0.6690\n",
      "Mất mát Xác thực: 0.1750, IoU Xác thực: 0.3759, F1-Score Xác thực: 0.5213\n",
      "Learning Rate hiện tại: 0.00000625\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 6/20\n",
      "Epoch 64/10000 Bắt đầu...\n",
      "Epoch 64/10000, Batch 10/188, Loss: 0.3473\n",
      "Epoch 64/10000, Batch 20/188, Loss: 0.1050\n",
      "Epoch 64/10000, Batch 30/188, Loss: 0.1334\n",
      "Epoch 64/10000, Batch 40/188, Loss: 0.1535\n",
      "Epoch 64/10000, Batch 50/188, Loss: 0.1056\n",
      "Epoch 64/10000, Batch 60/188, Loss: 0.1330\n",
      "Epoch 64/10000, Batch 70/188, Loss: 0.1624\n",
      "Epoch 64/10000, Batch 80/188, Loss: 0.1512\n",
      "Epoch 64/10000, Batch 90/188, Loss: 0.0730\n",
      "Epoch 64/10000, Batch 100/188, Loss: 0.3114\n",
      "Epoch 64/10000, Batch 110/188, Loss: 0.1727\n",
      "Epoch 64/10000, Batch 120/188, Loss: 0.1457\n",
      "Epoch 64/10000, Batch 130/188, Loss: 0.1079\n",
      "Epoch 64/10000, Batch 140/188, Loss: 0.3795\n",
      "Epoch 64/10000, Batch 150/188, Loss: 0.1516\n",
      "Epoch 64/10000, Batch 160/188, Loss: 0.2414\n",
      "Epoch 64/10000, Batch 170/188, Loss: 0.1148\n",
      "Epoch 64/10000, Batch 180/188, Loss: 0.1190\n",
      "Epoch 64 Kết thúc - Mất mát Huấn luyện: 0.1556, IoU Huấn luyện: 0.5103, F1-Score Huấn luyện: 0.6699\n",
      "Mất mát Xác thực: 0.1775, IoU Xác thực: 0.3693, F1-Score Xác thực: 0.5144\n",
      "Learning Rate hiện tại: 0.00000625\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 7/20\n",
      "Epoch 65/10000 Bắt đầu...\n",
      "Epoch 65/10000, Batch 10/188, Loss: 0.1244\n",
      "Epoch 65/10000, Batch 20/188, Loss: 0.1892\n",
      "Epoch 65/10000, Batch 30/188, Loss: 0.1723\n",
      "Epoch 65/10000, Batch 40/188, Loss: 0.3766\n",
      "Epoch 65/10000, Batch 50/188, Loss: 0.3015\n",
      "Epoch 65/10000, Batch 60/188, Loss: 0.3427\n",
      "Epoch 65/10000, Batch 70/188, Loss: 0.1359\n",
      "Epoch 65/10000, Batch 80/188, Loss: 0.1565\n",
      "Epoch 65/10000, Batch 90/188, Loss: 0.1959\n",
      "Epoch 65/10000, Batch 100/188, Loss: 0.1810\n",
      "Epoch 65/10000, Batch 110/188, Loss: 0.1605\n",
      "Epoch 65/10000, Batch 120/188, Loss: 0.1131\n",
      "Epoch 65/10000, Batch 130/188, Loss: 0.1050\n",
      "Epoch 65/10000, Batch 140/188, Loss: 0.1836\n",
      "Epoch 65/10000, Batch 150/188, Loss: 0.1987\n",
      "Epoch 65/10000, Batch 160/188, Loss: 0.1054\n",
      "Epoch 65/10000, Batch 170/188, Loss: 0.1176\n",
      "Epoch 65/10000, Batch 180/188, Loss: 0.1294\n",
      "Epoch 65 Kết thúc - Mất mát Huấn luyện: 0.1551, IoU Huấn luyện: 0.5106, F1-Score Huấn luyện: 0.6703\n",
      "Mất mát Xác thực: 0.1766, IoU Xác thực: 0.3714, F1-Score Xác thực: 0.5164\n",
      "Learning Rate hiện tại: 0.00000313\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 8/20\n",
      "Epoch 66/10000 Bắt đầu...\n",
      "Epoch 66/10000, Batch 10/188, Loss: 0.1222\n",
      "Epoch 66/10000, Batch 20/188, Loss: 0.1797\n",
      "Epoch 66/10000, Batch 30/188, Loss: 0.1646\n",
      "Epoch 66/10000, Batch 40/188, Loss: 0.2717\n",
      "Epoch 66/10000, Batch 50/188, Loss: 0.1002\n",
      "Epoch 66/10000, Batch 60/188, Loss: 0.1213\n",
      "Epoch 66/10000, Batch 70/188, Loss: 0.1297\n",
      "Epoch 66/10000, Batch 80/188, Loss: 0.1196\n",
      "Epoch 66/10000, Batch 90/188, Loss: 0.1528\n",
      "Epoch 66/10000, Batch 100/188, Loss: 0.1686\n",
      "Epoch 66/10000, Batch 110/188, Loss: 0.2425\n",
      "Epoch 66/10000, Batch 120/188, Loss: 0.2505\n",
      "Epoch 66/10000, Batch 130/188, Loss: 0.1672\n",
      "Epoch 66/10000, Batch 140/188, Loss: 0.1268\n",
      "Epoch 66/10000, Batch 150/188, Loss: 0.1256\n",
      "Epoch 66/10000, Batch 160/188, Loss: 0.1209\n",
      "Epoch 66/10000, Batch 170/188, Loss: 0.1660\n",
      "Epoch 66/10000, Batch 180/188, Loss: 0.1798\n",
      "Epoch 66 Kết thúc - Mất mát Huấn luyện: 0.1553, IoU Huấn luyện: 0.5089, F1-Score Huấn luyện: 0.6685\n",
      "Mất mát Xác thực: 0.1754, IoU Xác thực: 0.3800, F1-Score Xác thực: 0.5256\n",
      "Learning Rate hiện tại: 0.00000313\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 9/20\n",
      "Epoch 67/10000 Bắt đầu...\n",
      "Epoch 67/10000, Batch 10/188, Loss: 0.1191\n",
      "Epoch 67/10000, Batch 20/188, Loss: 0.1639\n",
      "Epoch 67/10000, Batch 30/188, Loss: 0.2920\n",
      "Epoch 67/10000, Batch 40/188, Loss: 0.1995\n",
      "Epoch 67/10000, Batch 50/188, Loss: 0.1586\n",
      "Epoch 67/10000, Batch 60/188, Loss: 0.1315\n",
      "Epoch 67/10000, Batch 70/188, Loss: 0.1275\n",
      "Epoch 67/10000, Batch 80/188, Loss: 0.1738\n",
      "Epoch 67/10000, Batch 90/188, Loss: 0.1964\n",
      "Epoch 67/10000, Batch 100/188, Loss: 0.1043\n",
      "Epoch 67/10000, Batch 110/188, Loss: 0.3321\n",
      "Epoch 67/10000, Batch 120/188, Loss: 0.1873\n",
      "Epoch 67/10000, Batch 130/188, Loss: 0.1456\n",
      "Epoch 67/10000, Batch 140/188, Loss: 0.1410\n",
      "Epoch 67/10000, Batch 150/188, Loss: 0.1723\n",
      "Epoch 67/10000, Batch 160/188, Loss: 0.1096\n",
      "Epoch 67/10000, Batch 170/188, Loss: 0.2071\n",
      "Epoch 67/10000, Batch 180/188, Loss: 0.1120\n",
      "Epoch 67 Kết thúc - Mất mát Huấn luyện: 0.1532, IoU Huấn luyện: 0.5100, F1-Score Huấn luyện: 0.6695\n",
      "Mất mát Xác thực: 0.1747, IoU Xác thực: 0.3833, F1-Score Xác thực: 0.5292\n",
      "Learning Rate hiện tại: 0.00000313\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 10/20\n",
      "Epoch 68/10000 Bắt đầu...\n",
      "Epoch 68/10000, Batch 10/188, Loss: 0.1387\n",
      "Epoch 68/10000, Batch 20/188, Loss: 0.1464\n",
      "Epoch 68/10000, Batch 30/188, Loss: 0.1656\n",
      "Epoch 68/10000, Batch 40/188, Loss: 0.1461\n",
      "Epoch 68/10000, Batch 50/188, Loss: 0.1062\n",
      "Epoch 68/10000, Batch 60/188, Loss: 0.0986\n",
      "Epoch 68/10000, Batch 70/188, Loss: 0.1746\n",
      "Epoch 68/10000, Batch 80/188, Loss: 0.1379\n",
      "Epoch 68/10000, Batch 90/188, Loss: 0.1725\n",
      "Epoch 68/10000, Batch 100/188, Loss: 0.1002\n",
      "Epoch 68/10000, Batch 110/188, Loss: 0.1590\n",
      "Epoch 68/10000, Batch 120/188, Loss: 0.1716\n",
      "Epoch 68/10000, Batch 130/188, Loss: 0.1088\n",
      "Epoch 68/10000, Batch 140/188, Loss: 0.1477\n",
      "Epoch 68/10000, Batch 150/188, Loss: 0.1489\n",
      "Epoch 68/10000, Batch 160/188, Loss: 0.1377\n",
      "Epoch 68/10000, Batch 170/188, Loss: 0.1835\n",
      "Epoch 68/10000, Batch 180/188, Loss: 0.1331\n",
      "Epoch 68 Kết thúc - Mất mát Huấn luyện: 0.1513, IoU Huấn luyện: 0.5099, F1-Score Huấn luyện: 0.6694\n",
      "Mất mát Xác thực: 0.1757, IoU Xác thực: 0.3807, F1-Score Xác thực: 0.5264\n",
      "Learning Rate hiện tại: 0.00000313\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 11/20\n",
      "Epoch 69/10000 Bắt đầu...\n",
      "Epoch 69/10000, Batch 10/188, Loss: 0.3347\n",
      "Epoch 69/10000, Batch 20/188, Loss: 0.1098\n",
      "Epoch 69/10000, Batch 30/188, Loss: 0.1544\n",
      "Epoch 69/10000, Batch 40/188, Loss: 0.1023\n",
      "Epoch 69/10000, Batch 50/188, Loss: 0.1592\n",
      "Epoch 69/10000, Batch 60/188, Loss: 0.3942\n",
      "Epoch 69/10000, Batch 70/188, Loss: 0.1206\n",
      "Epoch 69/10000, Batch 80/188, Loss: 0.1056\n",
      "Epoch 69/10000, Batch 90/188, Loss: 0.1413\n",
      "Epoch 69/10000, Batch 100/188, Loss: 0.1150\n",
      "Epoch 69/10000, Batch 110/188, Loss: 0.1082\n",
      "Epoch 69/10000, Batch 120/188, Loss: 0.1002\n",
      "Epoch 69/10000, Batch 130/188, Loss: 0.1927\n",
      "Epoch 69/10000, Batch 140/188, Loss: 0.1753\n",
      "Epoch 69/10000, Batch 150/188, Loss: 0.1169\n",
      "Epoch 69/10000, Batch 160/188, Loss: 0.1039\n",
      "Epoch 69/10000, Batch 170/188, Loss: 0.1192\n",
      "Epoch 69/10000, Batch 180/188, Loss: 0.1144\n",
      "Epoch 69 Kết thúc - Mất mát Huấn luyện: 0.1557, IoU Huấn luyện: 0.5154, F1-Score Huấn luyện: 0.6747\n",
      "Mất mát Xác thực: 0.1756, IoU Xác thực: 0.3730, F1-Score Xác thực: 0.5181\n",
      "Learning Rate hiện tại: 0.00000156\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 12/20\n",
      "Epoch 70/10000 Bắt đầu...\n",
      "Epoch 70/10000, Batch 10/188, Loss: 0.1231\n",
      "Epoch 70/10000, Batch 20/188, Loss: 0.1162\n",
      "Epoch 70/10000, Batch 30/188, Loss: 0.1269\n",
      "Epoch 70/10000, Batch 40/188, Loss: 0.1318\n",
      "Epoch 70/10000, Batch 50/188, Loss: 0.0861\n",
      "Epoch 70/10000, Batch 60/188, Loss: 0.1675\n",
      "Epoch 70/10000, Batch 70/188, Loss: 0.3161\n",
      "Epoch 70/10000, Batch 80/188, Loss: 0.1051\n",
      "Epoch 70/10000, Batch 90/188, Loss: 0.1235\n",
      "Epoch 70/10000, Batch 100/188, Loss: 0.1397\n",
      "Epoch 70/10000, Batch 110/188, Loss: 0.1668\n",
      "Epoch 70/10000, Batch 120/188, Loss: 0.2500\n",
      "Epoch 70/10000, Batch 130/188, Loss: 0.1127\n",
      "Epoch 70/10000, Batch 140/188, Loss: 0.1433\n",
      "Epoch 70/10000, Batch 150/188, Loss: 0.1715\n",
      "Epoch 70/10000, Batch 160/188, Loss: 0.1247\n",
      "Epoch 70/10000, Batch 170/188, Loss: 0.2305\n",
      "Epoch 70/10000, Batch 180/188, Loss: 0.0946\n",
      "Epoch 70 Kết thúc - Mất mát Huấn luyện: 0.1551, IoU Huấn luyện: 0.5077, F1-Score Huấn luyện: 0.6679\n",
      "Mất mát Xác thực: 0.1755, IoU Xác thực: 0.3768, F1-Score Xác thực: 0.5223\n",
      "Learning Rate hiện tại: 0.00000156\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 13/20\n",
      "Epoch 71/10000 Bắt đầu...\n",
      "Epoch 71/10000, Batch 10/188, Loss: 0.0947\n",
      "Epoch 71/10000, Batch 20/188, Loss: 0.1638\n",
      "Epoch 71/10000, Batch 30/188, Loss: 0.0940\n",
      "Epoch 71/10000, Batch 40/188, Loss: 0.0981\n",
      "Epoch 71/10000, Batch 50/188, Loss: 0.1307\n",
      "Epoch 71/10000, Batch 60/188, Loss: 0.1300\n",
      "Epoch 71/10000, Batch 70/188, Loss: 0.1412\n",
      "Epoch 71/10000, Batch 80/188, Loss: 0.2574\n",
      "Epoch 71/10000, Batch 90/188, Loss: 0.1101\n",
      "Epoch 71/10000, Batch 100/188, Loss: 0.1260\n",
      "Epoch 71/10000, Batch 110/188, Loss: 0.1187\n",
      "Epoch 71/10000, Batch 120/188, Loss: 0.1461\n",
      "Epoch 71/10000, Batch 130/188, Loss: 0.1144\n",
      "Epoch 71/10000, Batch 140/188, Loss: 0.1165\n",
      "Epoch 71/10000, Batch 150/188, Loss: 0.1117\n",
      "Epoch 71/10000, Batch 160/188, Loss: 0.1030\n",
      "Epoch 71/10000, Batch 170/188, Loss: 0.0974\n",
      "Epoch 71/10000, Batch 180/188, Loss: 0.1720\n",
      "Epoch 71 Kết thúc - Mất mát Huấn luyện: 0.1538, IoU Huấn luyện: 0.5059, F1-Score Huấn luyện: 0.6667\n",
      "Mất mát Xác thực: 0.1764, IoU Xác thực: 0.3800, F1-Score Xác thực: 0.5256\n",
      "Learning Rate hiện tại: 0.00000156\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 14/20\n",
      "Epoch 72/10000 Bắt đầu...\n",
      "Epoch 72/10000, Batch 10/188, Loss: 0.1802\n",
      "Epoch 72/10000, Batch 20/188, Loss: 0.1125\n",
      "Epoch 72/10000, Batch 30/188, Loss: 0.1648\n",
      "Epoch 72/10000, Batch 40/188, Loss: 0.2228\n",
      "Epoch 72/10000, Batch 50/188, Loss: 0.2132\n",
      "Epoch 72/10000, Batch 60/188, Loss: 0.1248\n",
      "Epoch 72/10000, Batch 70/188, Loss: 0.1945\n",
      "Epoch 72/10000, Batch 80/188, Loss: 0.1340\n",
      "Epoch 72/10000, Batch 90/188, Loss: 0.1451\n",
      "Epoch 72/10000, Batch 100/188, Loss: 0.1302\n",
      "Epoch 72/10000, Batch 110/188, Loss: 0.1182\n",
      "Epoch 72/10000, Batch 120/188, Loss: 0.2034\n",
      "Epoch 72/10000, Batch 130/188, Loss: 0.1295\n",
      "Epoch 72/10000, Batch 140/188, Loss: 0.1525\n",
      "Epoch 72/10000, Batch 150/188, Loss: 0.0924\n",
      "Epoch 72/10000, Batch 160/188, Loss: 0.1219\n",
      "Epoch 72/10000, Batch 170/188, Loss: 0.1589\n",
      "Epoch 72/10000, Batch 180/188, Loss: 0.1200\n",
      "Epoch 72 Kết thúc - Mất mát Huấn luyện: 0.1525, IoU Huấn luyện: 0.5147, F1-Score Huấn luyện: 0.6740\n",
      "Mất mát Xác thực: 0.1750, IoU Xác thực: 0.3781, F1-Score Xác thực: 0.5236\n",
      "Learning Rate hiện tại: 0.00000156\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 15/20\n",
      "Epoch 73/10000 Bắt đầu...\n",
      "Epoch 73/10000, Batch 10/188, Loss: 0.1025\n",
      "Epoch 73/10000, Batch 20/188, Loss: 0.1237\n",
      "Epoch 73/10000, Batch 30/188, Loss: 0.1328\n",
      "Epoch 73/10000, Batch 40/188, Loss: 0.1254\n",
      "Epoch 73/10000, Batch 50/188, Loss: 0.0672\n",
      "Epoch 73/10000, Batch 60/188, Loss: 0.1403\n",
      "Epoch 73/10000, Batch 70/188, Loss: 0.1174\n",
      "Epoch 73/10000, Batch 80/188, Loss: 0.0831\n",
      "Epoch 73/10000, Batch 90/188, Loss: 0.1281\n",
      "Epoch 73/10000, Batch 100/188, Loss: 0.1262\n",
      "Epoch 73/10000, Batch 110/188, Loss: 0.1227\n",
      "Epoch 73/10000, Batch 120/188, Loss: 0.1366\n",
      "Epoch 73/10000, Batch 130/188, Loss: 0.1415\n",
      "Epoch 73/10000, Batch 140/188, Loss: 0.1282\n",
      "Epoch 73/10000, Batch 150/188, Loss: 0.1196\n",
      "Epoch 73/10000, Batch 160/188, Loss: 0.2871\n",
      "Epoch 73/10000, Batch 170/188, Loss: 0.1277\n",
      "Epoch 73/10000, Batch 180/188, Loss: 0.1365\n",
      "Epoch 73 Kết thúc - Mất mát Huấn luyện: 0.1566, IoU Huấn luyện: 0.5131, F1-Score Huấn luyện: 0.6739\n",
      "Mất mát Xác thực: 0.1746, IoU Xác thực: 0.3744, F1-Score Xác thực: 0.5196\n",
      "Learning Rate hiện tại: 0.00000078\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 16/20\n",
      "Epoch 74/10000 Bắt đầu...\n",
      "Epoch 74/10000, Batch 10/188, Loss: 0.1493\n",
      "Epoch 74/10000, Batch 20/188, Loss: 0.1414\n",
      "Epoch 74/10000, Batch 30/188, Loss: 0.2404\n",
      "Epoch 74/10000, Batch 40/188, Loss: 0.1382\n",
      "Epoch 74/10000, Batch 50/188, Loss: 0.1354\n",
      "Epoch 74/10000, Batch 60/188, Loss: 0.1111\n",
      "Epoch 74/10000, Batch 70/188, Loss: 0.0661\n",
      "Epoch 74/10000, Batch 80/188, Loss: 0.1211\n",
      "Epoch 74/10000, Batch 90/188, Loss: 0.1217\n",
      "Epoch 74/10000, Batch 100/188, Loss: 0.1331\n",
      "Epoch 74/10000, Batch 110/188, Loss: 0.1596\n",
      "Epoch 74/10000, Batch 120/188, Loss: 0.1193\n",
      "Epoch 74/10000, Batch 130/188, Loss: 0.1219\n",
      "Epoch 74/10000, Batch 140/188, Loss: 0.1614\n",
      "Epoch 74/10000, Batch 150/188, Loss: 0.3536\n",
      "Epoch 74/10000, Batch 160/188, Loss: 0.1173\n",
      "Epoch 74/10000, Batch 170/188, Loss: 0.1298\n",
      "Epoch 74/10000, Batch 180/188, Loss: 0.1417\n",
      "Epoch 74 Kết thúc - Mất mát Huấn luyện: 0.1533, IoU Huấn luyện: 0.5114, F1-Score Huấn luyện: 0.6713\n",
      "Mất mát Xác thực: 0.1752, IoU Xác thực: 0.3784, F1-Score Xác thực: 0.5240\n",
      "Learning Rate hiện tại: 0.00000078\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 17/20\n",
      "Epoch 75/10000 Bắt đầu...\n",
      "Epoch 75/10000, Batch 10/188, Loss: 0.1810\n",
      "Epoch 75/10000, Batch 20/188, Loss: 0.1661\n",
      "Epoch 75/10000, Batch 30/188, Loss: 0.1562\n",
      "Epoch 75/10000, Batch 40/188, Loss: 0.1316\n",
      "Epoch 75/10000, Batch 50/188, Loss: 0.1329\n",
      "Epoch 75/10000, Batch 60/188, Loss: 0.1573\n",
      "Epoch 75/10000, Batch 70/188, Loss: 0.1296\n",
      "Epoch 75/10000, Batch 80/188, Loss: 0.1952\n",
      "Epoch 75/10000, Batch 90/188, Loss: 0.1008\n",
      "Epoch 75/10000, Batch 100/188, Loss: 0.1752\n",
      "Epoch 75/10000, Batch 110/188, Loss: 0.1464\n",
      "Epoch 75/10000, Batch 120/188, Loss: 0.6022\n",
      "Epoch 75/10000, Batch 130/188, Loss: 0.1568\n",
      "Epoch 75/10000, Batch 140/188, Loss: 0.0795\n",
      "Epoch 75/10000, Batch 150/188, Loss: 0.1507\n",
      "Epoch 75/10000, Batch 160/188, Loss: 0.1605\n",
      "Epoch 75/10000, Batch 170/188, Loss: 0.1432\n",
      "Epoch 75/10000, Batch 180/188, Loss: 0.1704\n",
      "Epoch 75 Kết thúc - Mất mát Huấn luyện: 0.1540, IoU Huấn luyện: 0.5082, F1-Score Huấn luyện: 0.6678\n",
      "Mất mát Xác thực: 0.1741, IoU Xác thực: 0.3801, F1-Score Xác thực: 0.5259\n",
      "Learning Rate hiện tại: 0.00000078\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 18/20\n",
      "Epoch 76/10000 Bắt đầu...\n",
      "Epoch 76/10000, Batch 10/188, Loss: 0.2079\n",
      "Epoch 76/10000, Batch 20/188, Loss: 0.1486\n",
      "Epoch 76/10000, Batch 30/188, Loss: 0.0805\n",
      "Epoch 76/10000, Batch 40/188, Loss: 0.1528\n",
      "Epoch 76/10000, Batch 50/188, Loss: 0.0981\n",
      "Epoch 76/10000, Batch 60/188, Loss: 0.1307\n",
      "Epoch 76/10000, Batch 70/188, Loss: 0.1564\n",
      "Epoch 76/10000, Batch 80/188, Loss: 0.0927\n",
      "Epoch 76/10000, Batch 90/188, Loss: 0.1105\n",
      "Epoch 76/10000, Batch 100/188, Loss: 0.1084\n",
      "Epoch 76/10000, Batch 110/188, Loss: 0.1653\n",
      "Epoch 76/10000, Batch 120/188, Loss: 0.1625\n",
      "Epoch 76/10000, Batch 130/188, Loss: 0.1687\n",
      "Epoch 76/10000, Batch 140/188, Loss: 0.1990\n",
      "Epoch 76/10000, Batch 150/188, Loss: 0.1340\n",
      "Epoch 76/10000, Batch 160/188, Loss: 0.1725\n",
      "Epoch 76/10000, Batch 170/188, Loss: 0.1103\n",
      "Epoch 76/10000, Batch 180/188, Loss: 0.1441\n",
      "Epoch 76 Kết thúc - Mất mát Huấn luyện: 0.1524, IoU Huấn luyện: 0.5106, F1-Score Huấn luyện: 0.6696\n",
      "Mất mát Xác thực: 0.1745, IoU Xác thực: 0.3766, F1-Score Xác thực: 0.5219\n",
      "Learning Rate hiện tại: 0.00000078\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 19/20\n",
      "Epoch 77/10000 Bắt đầu...\n",
      "Epoch 77/10000, Batch 10/188, Loss: 0.1495\n",
      "Epoch 77/10000, Batch 20/188, Loss: 0.1084\n",
      "Epoch 77/10000, Batch 30/188, Loss: 0.1375\n",
      "Epoch 77/10000, Batch 40/188, Loss: 0.1872\n",
      "Epoch 77/10000, Batch 50/188, Loss: 0.1056\n",
      "Epoch 77/10000, Batch 60/188, Loss: 0.1373\n",
      "Epoch 77/10000, Batch 70/188, Loss: 0.1989\n",
      "Epoch 77/10000, Batch 80/188, Loss: 0.1140\n",
      "Epoch 77/10000, Batch 90/188, Loss: 0.1729\n",
      "Epoch 77/10000, Batch 100/188, Loss: 0.0804\n",
      "Epoch 77/10000, Batch 110/188, Loss: 0.2366\n",
      "Epoch 77/10000, Batch 120/188, Loss: 0.1617\n",
      "Epoch 77/10000, Batch 130/188, Loss: 0.1478\n",
      "Epoch 77/10000, Batch 140/188, Loss: 0.1510\n",
      "Epoch 77/10000, Batch 150/188, Loss: 0.1640\n",
      "Epoch 77/10000, Batch 160/188, Loss: 0.1235\n",
      "Epoch 77/10000, Batch 170/188, Loss: 0.1884\n",
      "Epoch 77/10000, Batch 180/188, Loss: 0.1351\n",
      "Epoch 77 Kết thúc - Mất mát Huấn luyện: 0.1522, IoU Huấn luyện: 0.5115, F1-Score Huấn luyện: 0.6708\n",
      "Mất mát Xác thực: 0.1754, IoU Xác thực: 0.3805, F1-Score Xác thực: 0.5262\n",
      "Learning Rate hiện tại: 0.00000039\n",
      "Mất mát xác thực không cải thiện. Sự kiên nhẫn: 20/20\n",
      "Dừng sớm!\n",
      "\n",
      "Quá trình huấn luyện đã hoàn tất.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CrackDetectionDataset(train_img_paths, train_mask_paths, augment=True)\n",
    "val_dataset = CrackDetectionDataset(val_img_paths, val_mask_paths, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# --- Khởi tạo mô hình, optimizer, criterion ---\n",
    "model = SwinUNet(input_channels=3, num_classes=1).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "my_pos_weight = 11.33\n",
    "\n",
    "pos_weight_tensor = torch.tensor(my_pos_weight, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "print(model)\n",
    "\n",
    "callbacks_config = {\n",
    "    'patience': 20,\n",
    "    'checkpoint_path': 'swin_unet_best_pytorchv2.pth'\n",
    "}\n",
    "\n",
    "start_epoch = 0\n",
    "best_val_loss_so_far = float('inf')\n",
    "checkpoint_path = callbacks_config['checkpoint_path']\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Phát hiện checkpoint tại {checkpoint_path}. Đang tải để tiếp tục huấn luyện...\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1 \n",
    "    best_val_loss_so_far = checkpoint['best_val_loss']\n",
    "    \n",
    "    print(f\"Đã tải checkpoint từ Epoch {start_epoch-1}. Tiếp tục huấn luyện từ Epoch {start_epoch}.\")\n",
    "    print(f\"Mất mát xác thực tốt nhất trước đó: {best_val_loss_so_far:.4f}\")\n",
    "else:\n",
    "    print(\"Không tìm thấy checkpoint. Bắt đầu huấn luyện từ đầu (Epoch 0).\")\n",
    "\n",
    "print(\"\\nBắt đầu huấn luyện mô hình Swin-Unet...\")\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, scheduler,\n",
    "            num_epochs=10000, callbacks_config=callbacks_config,\n",
    "            start_epoch=start_epoch, best_val_loss_so_far=best_val_loss_so_far)\n",
    "\n",
    "print(\"\\nQuá trình huấn luyện đã hoàn tất.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
